{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter definition\n",
    "Choose all the settings for the database creation. Input, output dir..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "home = os.path.expanduser(\"~\")\n",
    "\n",
    "db_name=  'emb_enfsi_2011' #'test_new_creators_4'\n",
    "input_dir = os.path.join(home, 'video_resources', 'image_datasets')\n",
    "output_dir = os.path.join(home, 'video_resources', 'sql_database')\n",
    "database_names=['enfsi'] # 'lfw', 'scface',  'enfsi', 'enfsi2015', 'xqlfw', 'utkface','chokepoint','forenface'\n",
    "detector_names=['mtcnn'] # 'dlib', 'mtcnn', 'mtcnn_serfiq'\n",
    "embedding_model_names=[\"QMagFace\"] # , \"Dlib\", \"ArcFace\",\n",
    "attributes_to_update=[]  # 'gender', 'age', 'emotion', 'race'\n",
    "quality_model_names = ['ser_fiq', 'tface'] # 'confusion_score', 'ser_fiq',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SERFIQ model\n",
    "\n",
    "Create SERFIQ model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/anaconda3/envs/sql-face/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[12:37:19] ../src/nnvm/legacy_json_util.cc:208: Loading symbol saved by previous version v1.8.0. Attempting to upgrade...\n",
      "[12:37:19] ../src/nnvm/legacy_json_util.cc:216: Symbol successfully upgraded!\n",
      "/home/andrea/anaconda3/envs/sql-face/lib/python3.8/site-packages/mxnet/gluon/block.py:1784: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\n",
      "\tdata: None\n",
      "  input_sym_arg_type = in_param.infer_type()[0]\n",
      "[12:37:19] ../src/base.cc:79: cuDNN lib mismatch: linked-against version 8100 != compiled-against version 8101.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n",
      "[12:37:28] ../src/nnvm/legacy_json_util.cc:208: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\n",
      "[12:37:28] ../src/nnvm/legacy_json_util.cc:216: Symbol successfully upgraded!\n",
      "[12:37:28] ../src/nnvm/legacy_json_util.cc:208: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\n",
      "[12:37:28] ../src/nnvm/legacy_json_util.cc:216: Symbol successfully upgraded!\n",
      "[12:37:28] ../src/nnvm/legacy_json_util.cc:208: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\n",
      "[12:37:28] ../src/nnvm/legacy_json_util.cc:216: Symbol successfully upgraded!\n",
      "[12:37:28] ../src/nnvm/legacy_json_util.cc:208: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\n",
      "[12:37:28] ../src/nnvm/legacy_json_util.cc:216: Symbol successfully upgraded!\n"
     ]
    }
   ],
   "source": [
    "from sql_face.serfiq import get_serfiq_model\n",
    "serfiq = get_serfiq_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "database = SQLDataBase(db_name=db_name,\n",
    "                        database_names=database_names, # , 'scface', 'forenface', 'enfsi', 'enfsi2015'\n",
    "                        detector_names=detector_names,\n",
    "                        embedding_model_names=embedding_model_names,\n",
    "                        quality_model_names=quality_model_names,\n",
    "                        save_in_drive=save_in_drive                        \n",
    "                        )\n",
    "\n",
    "database.fill_db()\n",
    "database.update_db(attributes_to_update=attributes_to_update, force_update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 12:37:28.446195: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 12:37:29.663834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/andrea/anaconda3/envs/sql-face/lib/python3.8/site-packages/cv2/../../lib64:/home/andrea/Documents/cuda_software/cuda/lib64:/usr/local/cuda-11.2/lib64\n",
      "2023-01-21 12:37:29.663922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/andrea/anaconda3/envs/sql-face/lib/python3.8/site-packages/cv2/../../lib64:/home/andrea/Documents/cuda_software/cuda/lib64:/usr/local/cuda-11.2/lib64\n",
      "2023-01-21 12:37:29.663931: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from sql_face.sqldb import SQLDataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = SQLDataBase(db_name=db_name,\n",
    "                        input_dir = input_dir,\n",
    "                        output_dir_name = output_dir,\n",
    "                        database_names = database_names,\n",
    "                        detector_names = detector_names,\n",
    "                        embedding_model_names = embedding_model_names,\n",
    "                        quality_model_names = quality_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'db_name': 'emb_enfsi_2011',\n",
       " 'input_dir': '/home/andrea/video_resources/image_datasets',\n",
       " 'save_in_drive': False,\n",
       " 'output_dir': '/home/andrea/video_resources/sql_database',\n",
       " 'session': <sqlalchemy.orm.session.Session at 0x7f5274185b20>,\n",
       " 'databases': [<sql_face.databases.Enfsi at 0x7f5274185b80>],\n",
       " 'detector_names': ['mtcnn'],\n",
       " 'embedding_model_names': ['QMagFace'],\n",
       " 'quality_model_names': ['ser_fiq', 'tface']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# from sql_face.tables import EnfsiPair, EnfsiPair2015, QualityImage, FaceImage, CroppedImage\n",
    "\n",
    "# session = database.session\n",
    "\n",
    "# \"\"\" pd.read_sql_query(\n",
    "#     sql = session.query(Students.first_name,\n",
    "#                         Students.last_name).filter(\n",
    "#       Students.score > 80).statement, con = engine) \"\"\"\n",
    "\n",
    "# # generamos un datafame con la información que necesitamos para los registros sin quality\n",
    "# # hacemos una query para actualizar los registros que no tienen quality\n",
    "\n",
    "\n",
    "# df_a = pd.read_sql_query(session.query(QualityImage,FaceImage.embeddingModel_id,FaceImage.croppedImage_id)\n",
    "#     .join(FaceImage)\n",
    "#     .filter(QualityImage.quality != None,FaceImage.embeddingModel_id == 1).statement, con=session.bind)\n",
    "\n",
    "\n",
    "# sql_b = (session.query(QualityImage, FaceImage)\n",
    "#     .join(FaceImage)\n",
    "#     .filter(QualityImage.quality == None).all())\n",
    "# n1 = 100\n",
    "# n = n1\n",
    "# for Q,F in tqdm(sql_b):\n",
    "#     #recorremos el resultado y actualizamos el objeto QualityImage\n",
    "\n",
    "\n",
    "#     qm = Q.qualityModel_id\n",
    "#     em = F.embeddingModel_id\n",
    "#     ci = F.croppedImage_id\n",
    "\n",
    "#     df_r = df_a.loc[(df_a['qualityModel_id'] == qm) & (df_a['croppedImage_id'] == ci) & (df_a['embeddingModel_id']== 1)]\n",
    "#     assert len(df_r) == 1\n",
    "#     Q.quality = float(df_r.quality)\n",
    "#     if not n:\n",
    "#         session.commit()\n",
    "#         n = n1\n",
    "#     else:\n",
    "#         n-=1\n",
    "# session.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CroppedImages for detector mtcnn: 0it [00:00, ?it/s]\n",
      "Face images in QMagFace: 0it [00:00, ?it/s]00<?, ?it/s]\n",
      "Embedding models: 100%|██████████| 1/1 [00:00<00:00, 288.17it/s]\n",
      "Quality images in ser_fiq: 100%|██████████| 75/75 [00:00<00:00, 62070.40it/s]\n",
      "Quality images in tface: 0it [00:00, ?it/s]\n",
      "Quality models: 100%|██████████| 2/2 [00:00<00:00, 216.14it/s]\n"
     ]
    }
   ],
   "source": [
    "database.create_tables(serfiq=serfiq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Update cropped images: 0it [00:00, ?it/s]\n",
      "Computing embeddings DeepFace: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading pth from models/qmagface/magface_epoch_00025.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings QMagFace:   0%|          | 0/375 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1152,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m database\u001b[39m.\u001b[39;49mupdate_tables(attributes_to_update, serfiq \u001b[39m=\u001b[39;49m serfiq)\n",
      "File \u001b[0;32m~/PycharmProjects/sql-face/sql_face/sqldb.py:75\u001b[0m, in \u001b[0;36mSQLDataBase.update_tables\u001b[0;34m(self, attributes_to_update, force_update, serfiq)\u001b[0m\n\u001b[1;32m     73\u001b[0m update_images(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatabases, attributes_to_update, force_update \u001b[39m=\u001b[39m force_update)\n\u001b[1;32m     74\u001b[0m update_cropped_images(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dir, force_update \u001b[39m=\u001b[39m force_update, serfiq \u001b[39m=\u001b[39m serfiq)\n\u001b[0;32m---> 75\u001b[0m update_face_images(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_dir, force_update \u001b[39m=\u001b[39;49m force_update)\n\u001b[1;32m     76\u001b[0m update_quality_images(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dir, serfiq \u001b[39m=\u001b[39m serfiq, force_update \u001b[39m=\u001b[39m force_update)\n",
      "File \u001b[0;32m~/PycharmProjects/sql-face/sql_face/alchemy.py:456\u001b[0m, in \u001b[0;36mupdate_face_images\u001b[0;34m(session, input_dir, force_update)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_face_images\u001b[39m(session, input_dir:\u001b[39mstr\u001b[39m, force_update: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    455\u001b[0m     update_embeddings_deepface(session, input_dir, force_update)\n\u001b[0;32m--> 456\u001b[0m     update_embeddings_qmagface(session, input_dir, force_update)\n",
      "File \u001b[0;32m~/PycharmProjects/sql-face/sql_face/alchemy.py:497\u001b[0m, in \u001b[0;36mupdate_embeddings_qmagface\u001b[0;34m(session, input_dir, force_update)\u001b[0m\n\u001b[1;32m    494\u001b[0m model \u001b[39m=\u001b[39m get_model()\n\u001b[1;32m    496\u001b[0m \u001b[39mfor\u001b[39;00m face_img \u001b[39min\u001b[39;00m tqdm(all_face_img, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mComputing embeddings QMagFace\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 497\u001b[0m     img \u001b[39m=\u001b[39m face_img\u001b[39m.\u001b[39;49mCroppedImage\u001b[39m.\u001b[39;49mget_aligned_image(input_dir)\n\u001b[1;32m    498\u001b[0m     embedding \u001b[39m=\u001b[39m compute_qmagface_embeddings(img, model)\n\u001b[1;32m    499\u001b[0m     face_img\u001b[39m.\u001b[39mFaceImage\u001b[39m.\u001b[39membeddings \u001b[39m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/PycharmProjects/sql-face/sql_face/tables.py:440\u001b[0m, in \u001b[0;36mCroppedImage.get_aligned_image\u001b[0;34m(self, input_dir, target_size, ser_fiq)\u001b[0m\n\u001b[1;32m    437\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages\u001b[39m.\u001b[39mget_image(input_dir)\n\u001b[1;32m    438\u001b[0m \u001b[39m#img_abs_path = os.path.join(input_dir, self.images.path)\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39m#aligned_img = DeepFace.detectFace(img_path = img_abs_path, \u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m aligned_img \u001b[39m=\u001b[39m DeepFace\u001b[39m.\u001b[39;49mdetectFace(img_path \u001b[39m=\u001b[39;49m image, \n\u001b[1;32m    441\u001b[0m target_size \u001b[39m=\u001b[39;49m target_size, \n\u001b[1;32m    442\u001b[0m detector_backend \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdetectors\u001b[39m.\u001b[39;49mname, \n\u001b[1;32m    443\u001b[0m align\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    444\u001b[0m enforce_detection\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    445\u001b[0m \u001b[39mreturn\u001b[39;00m aligned_img\u001b[39m*\u001b[39m\u001b[39m255\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/sql-face/lib/python3.8/site-packages/deepface/DeepFace.py:819\u001b[0m, in \u001b[0;36mdetectFace\u001b[0;34m(img_path, target_size, detector_backend, enforce_detection, align)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetectFace\u001b[39m(img_path, target_size \u001b[39m=\u001b[39m (\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m), detector_backend \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mopencv\u001b[39m\u001b[39m'\u001b[39m, enforce_detection \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, align \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    807\u001b[0m \u001b[39m\t\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[39m\tThis function applies pre-processing stages of a face recognition pipeline including detection and alignment\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m\t\tdeteced and aligned face in numpy format\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m\t\"\"\"\u001b[39;00m\n\u001b[0;32m--> 819\u001b[0m \timg \u001b[39m=\u001b[39m functions\u001b[39m.\u001b[39;49mpreprocess_face(img \u001b[39m=\u001b[39;49m img_path, target_size \u001b[39m=\u001b[39;49m target_size, detector_backend \u001b[39m=\u001b[39;49m detector_backend\n\u001b[1;32m    820\u001b[0m \t\t, enforce_detection \u001b[39m=\u001b[39;49m enforce_detection, align \u001b[39m=\u001b[39;49m align)[\u001b[39m0\u001b[39m] \u001b[39m#preprocess_face returns (1, 224, 224, 3)\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \t\u001b[39mreturn\u001b[39;00m img[:, :, ::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/sql-face/lib/python3.8/site-packages/deepface/commons/functions.py:178\u001b[0m, in \u001b[0;36mpreprocess_face\u001b[0;34m(img, target_size, grayscale, enforce_detection, detector_backend, return_region, align)\u001b[0m\n\u001b[1;32m    175\u001b[0m img \u001b[39m=\u001b[39m load_image(img)\n\u001b[1;32m    176\u001b[0m base_img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m--> 178\u001b[0m img, region \u001b[39m=\u001b[39m detect_face(img \u001b[39m=\u001b[39;49m img, detector_backend \u001b[39m=\u001b[39;49m detector_backend, grayscale \u001b[39m=\u001b[39;49m grayscale, enforce_detection \u001b[39m=\u001b[39;49m enforce_detection, align \u001b[39m=\u001b[39;49m align)\n\u001b[1;32m    180\u001b[0m \u001b[39m#--------------------------\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m img\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sql-face/lib/python3.8/site-packages/deepface/commons/functions.py:110\u001b[0m, in \u001b[0;36mdetect_face\u001b[0;34m(img, detector_backend, grayscale, enforce_detection, align)\u001b[0m\n\u001b[1;32m    103\u001b[0m \t\u001b[39mreturn\u001b[39;00m img, img_region\n\u001b[1;32m    105\u001b[0m \u001b[39m#----------------------------------------------\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[39m#detector stored in a global variable in FaceDetector object.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m#this call should be completed very fast because it will return found in memory\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m#it will not build face detector model in each call (consider for loops)\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m face_detector \u001b[39m=\u001b[39m FaceDetector\u001b[39m.\u001b[39;49mbuild_model(detector_backend)\n\u001b[1;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m \tdetected_face, img_region \u001b[39m=\u001b[39m FaceDetector\u001b[39m.\u001b[39mdetect_face(face_detector, detector_backend, img, align)\n",
      "File \u001b[0;32m~/anaconda3/envs/sql-face/lib/python3.8/site-packages/deepface/detectors/FaceDetector.py:27\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(detector_backend)\u001b[0m\n\u001b[1;32m     24\u001b[0m face_detector \u001b[39m=\u001b[39m backends\u001b[39m.\u001b[39mget(detector_backend)\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m face_detector:\n\u001b[0;32m---> 27\u001b[0m     face_detector \u001b[39m=\u001b[39m face_detector()\n\u001b[1;32m     28\u001b[0m     face_detector_obj[detector_backend] \u001b[39m=\u001b[39m face_detector\n\u001b[1;32m     29\u001b[0m     \u001b[39m#print(detector_backend,\" built\")\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sql-face/lib/python3.8/site-packages/deepface/detectors/MtcnnWrapper.py:6\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_model\u001b[39m():\n\u001b[1;32m      5\u001b[0m \t\u001b[39mfrom\u001b[39;00m \u001b[39mmtcnn\u001b[39;00m \u001b[39mimport\u001b[39;00m MTCNN\n\u001b[0;32m----> 6\u001b[0m \tface_detector \u001b[39m=\u001b[39m MTCNN()\n\u001b[1;32m      7\u001b[0m \t\u001b[39mreturn\u001b[39;00m face_detector\n",
      "File \u001b[0;32m~/anaconda3/envs/sql-face/lib/python3.8/site-packages/mtcnn/mtcnn.py:87\u001b[0m, in \u001b[0;36mMTCNN.__init__\u001b[0;34m(self, weights_file, min_face_size, steps_threshold, scale_factor)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_threshold \u001b[39m=\u001b[39m steps_threshold\n\u001b[1;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scale_factor \u001b[39m=\u001b[39m scale_factor\n\u001b[0;32m---> 87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pnet, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rnet, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_onet \u001b[39m=\u001b[39m NetworkFactory()\u001b[39m.\u001b[39;49mbuild_P_R_O_nets_from_file(weights_file)\n",
      "File \u001b[0;32m~/anaconda3/envs/sql-face/lib/python3.8/site-packages/mtcnn/network/factory.py:125\u001b[0m, in \u001b[0;36mNetworkFactory.build_P_R_O_nets_from_file\u001b[0;34m(self, weights_file)\u001b[0m\n\u001b[1;32m    123\u001b[0m p_net \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_pnet()\n\u001b[1;32m    124\u001b[0m r_net \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_rnet()\n\u001b[0;32m--> 125\u001b[0m o_net \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_onet()\n\u001b[1;32m    127\u001b[0m p_net\u001b[39m.\u001b[39mset_weights(weights[\u001b[39m'\u001b[39m\u001b[39mpnet\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    128\u001b[0m r_net\u001b[39m.\u001b[39mset_weights(weights[\u001b[39m'\u001b[39m\u001b[39mrnet\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/sql-face/lib/python3.8/site-packages/mtcnn/network/factory.py:109\u001b[0m, in \u001b[0;36mNetworkFactory.build_onet\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    106\u001b[0m o_layer \u001b[39m=\u001b[39m PReLU(shared_axes\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m])(o_layer)\n\u001b[1;32m    108\u001b[0m o_layer \u001b[39m=\u001b[39m Flatten()(o_layer)\n\u001b[0;32m--> 109\u001b[0m o_layer \u001b[39m=\u001b[39m Dense(\u001b[39m256\u001b[39;49m)(o_layer)\n\u001b[1;32m    110\u001b[0m o_layer \u001b[39m=\u001b[39m PReLU()(o_layer)\n\u001b[1;32m    112\u001b[0m o_layer_out1 \u001b[39m=\u001b[39m Dense(\u001b[39m2\u001b[39m)(o_layer)\n",
      "File \u001b[0;32m~/anaconda3/envs/sql-face/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/sql-face/lib/python3.8/site-packages/keras/backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[39mif\u001b[39;00m nonce:\n\u001b[1;32m   2099\u001b[0m         seed \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2100\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mstateless_uniform(\n\u001b[1;32m   2101\u001b[0m         shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   2102\u001b[0m         minval\u001b[39m=\u001b[39;49mminval,\n\u001b[1;32m   2103\u001b[0m         maxval\u001b[39m=\u001b[39;49mmaxval,\n\u001b[1;32m   2104\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2105\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m   2106\u001b[0m     )\n\u001b[1;32m   2107\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\n\u001b[1;32m   2108\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[1;32m   2109\u001b[0m     minval\u001b[39m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2113\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1152,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformV2]"
     ]
    }
   ],
   "source": [
    "database.update_tables(attributes_to_update, serfiq = serfiq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql-face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a84f744ed89671113ba95f00e1aad6d21abade608318eb8af248311f249adcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
