{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SER-FIQ\n",
    "\n",
    "> Face Image Quality model from [Terhorst](https://github.com/pterhoer/FaceImageQuality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp serfiq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "#Face preprocess\n",
    "import numpy as np\n",
    "from skimage import transform as trans\n",
    "\n",
    "#Mtcnn detector\n",
    "# coding: utf-8\n",
    "import os\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat\n",
    "# Note: Coomen if there are issues with zip and izip.\n",
    "# try:\n",
    "#     from itertools import izip\n",
    "# except ImportError:\n",
    "#     izip = zip\n",
    "izip = zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "izip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face preprocess\n",
    "Image cropping and alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def parse_lst_line(line):\n",
    "  vec = line.strip().split(\"\\t\")\n",
    "  assert len(vec)>=3\n",
    "  aligned = int(vec[0])\n",
    "  image_path = vec[1]\n",
    "  label = int(vec[2])\n",
    "  bbox = None\n",
    "  landmark = None\n",
    "  #print(vec)\n",
    "  if len(vec)>3:\n",
    "    bbox = np.zeros( (4,), dtype=np.int32)\n",
    "    for i in xrange(3,7):\n",
    "      bbox[i-3] = int(vec[i])\n",
    "    landmark = None\n",
    "    if len(vec)>7:\n",
    "      _l = []\n",
    "      for i in xrange(7,17):\n",
    "        _l.append(float(vec[i]))\n",
    "      landmark = np.array(_l).reshape( (2,5) ).T\n",
    "  #print(aligned)\n",
    "  return image_path, label, bbox, landmark, aligned\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_image(img_path, **kwargs):\n",
    "  mode = kwargs.get('mode', 'rgb')\n",
    "  layout = kwargs.get('layout', 'HWC')\n",
    "  if mode=='gray':\n",
    "    img = cv2.imread(img_path, cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "  else:\n",
    "    img = cv2.imread(img_path, cv2.CV_LOAD_IMAGE_COLOR)\n",
    "    if mode=='rgb':\n",
    "      #print('to rgb')\n",
    "      img = img[...,::-1]\n",
    "    if layout=='CHW':\n",
    "      img = np.transpose(img, (2,0,1))\n",
    "  return img\n",
    "\n",
    "\n",
    "def preprocess(img, bbox=None, landmark=None, **kwargs):\n",
    "  if isinstance(img, str):\n",
    "    img = read_image(img, **kwargs)\n",
    "  M = None\n",
    "  image_size = []\n",
    "  str_image_size = kwargs.get('image_size', '')\n",
    "  if len(str_image_size)>0:\n",
    "    image_size = [int(x) for x in str_image_size.split(',')]\n",
    "    if len(image_size)==1:\n",
    "      image_size = [image_size[0], image_size[0]]\n",
    "    assert len(image_size)==2\n",
    "    assert image_size[0]==112\n",
    "    assert image_size[0]==112 or image_size[1]==96\n",
    "  if landmark is not None:\n",
    "    assert len(image_size)==2\n",
    "    src = np.array([\n",
    "      [30.2946, 51.6963],\n",
    "      [65.5318, 51.5014],\n",
    "      [48.0252, 71.7366],\n",
    "      [33.5493, 92.3655],\n",
    "      [62.7299, 92.2041] ], dtype=np.float32 )\n",
    "    if image_size[1]==112:\n",
    "      src[:,0] += 8.0\n",
    "    dst = landmark.astype(np.float32)\n",
    "\n",
    "    tform = trans.SimilarityTransform()\n",
    "    tform.estimate(dst, src)\n",
    "    M = tform.params[0:2,:]\n",
    "    #M = cv2.estimateRigidTransform( dst.reshape(1,5,2), src.reshape(1,5,2), False)\n",
    "\n",
    "  if M is None:\n",
    "    if bbox is None: #use center crop\n",
    "      det = np.zeros(4, dtype=np.int32)\n",
    "      det[0] = int(img.shape[1]*0.0625)\n",
    "      det[1] = int(img.shape[0]*0.0625)\n",
    "      det[2] = img.shape[1] - det[0]\n",
    "      det[3] = img.shape[0] - det[1]\n",
    "    else:\n",
    "      det = bbox\n",
    "    margin = kwargs.get('margin', 44)\n",
    "    bb = np.zeros(4, dtype=np.int32)\n",
    "    bb[0] = np.maximum(det[0]-margin/2, 0)\n",
    "    bb[1] = np.maximum(det[1]-margin/2, 0)\n",
    "    bb[2] = np.minimum(det[2]+margin/2, img.shape[1])\n",
    "    bb[3] = np.minimum(det[3]+margin/2, img.shape[0])\n",
    "    ret = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "    if len(image_size)>0:\n",
    "      ret = cv2.resize(ret, (image_size[1], image_size[0]))\n",
    "    return ret \n",
    "  else: #do align using landmark\n",
    "    assert len(image_size)==2\n",
    "\n",
    "    #src = src[0:3,:]\n",
    "    #dst = dst[0:3,:]\n",
    "\n",
    "\n",
    "    #print(src.shape, dst.shape)\n",
    "    #print(src)\n",
    "    #print(dst)\n",
    "    #print(M)\n",
    "    warped = cv2.warpAffine(img,M,(image_size[1],image_size[0]), borderValue = 0.0)\n",
    "\n",
    "    #tform3 = trans.ProjectiveTransform()\n",
    "    #tform3.estimate(src, dst)\n",
    "    #warped = trans.warp(img, tform3, output_shape=_shape)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTCNN Detector\n",
    "Insightface implementation of this detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "\n",
    "class MtcnnDetector(object):\n",
    "    \"\"\"\n",
    "        Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks\n",
    "        see https://github.com/kpzhang93/MTCNN_face_detection_alignment\n",
    "        this is a mxnet version\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model_folder='./models/insightface',\n",
    "                 minsize = 20,\n",
    "                 threshold = [0.6, 0.7, 0.8],\n",
    "                 factor = 0.709,\n",
    "                 num_worker = 1,\n",
    "                 accurate_landmark = False,\n",
    "                 ctx=mx.cpu()):\n",
    "        \"\"\"\n",
    "            Initialize the detector\n",
    "\n",
    "            Parameters:\n",
    "            ----------\n",
    "                model_folder : string\n",
    "                    path for the models\n",
    "                minsize : float number\n",
    "                    minimal face to detect\n",
    "                threshold : float number\n",
    "                    detect threshold for 3 stages\n",
    "                factor: float number\n",
    "                    scale factor for image pyramid\n",
    "                num_worker: int number\n",
    "                    number of processes we use for first stage\n",
    "                accurate_landmark: bool\n",
    "                    use accurate landmark localization or not\n",
    "\n",
    "        \"\"\"\n",
    "        self.num_worker = num_worker\n",
    "        self.accurate_landmark = accurate_landmark\n",
    "\n",
    "        # load 4 models from folder\n",
    "        models = ['det1', 'det2', 'det3','det4']\n",
    "        models = [ os.path.join(model_folder, f) for f in models]\n",
    "        \n",
    "        self.PNets = []\n",
    "        for i in range(num_worker):\n",
    "            workner_net = mx.model.FeedForward.load(models[0], 1, ctx=ctx)\n",
    "            self.PNets.append(workner_net)\n",
    "\n",
    "        #self.Pool = Pool(num_worker)\n",
    "\n",
    "        self.RNet = mx.model.FeedForward.load(models[1], 1, ctx=ctx)\n",
    "        self.ONet = mx.model.FeedForward.load(models[2], 1, ctx=ctx)\n",
    "        self.LNet = mx.model.FeedForward.load(models[3], 1, ctx=ctx)\n",
    "\n",
    "        self.minsize   = float(minsize)\n",
    "        self.factor    = float(factor)\n",
    "        self.threshold = threshold\n",
    "\n",
    "\n",
    "    def convert_to_square(self, bbox):\n",
    "        \"\"\"\n",
    "            convert bbox to square\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "            bbox: numpy array , shape n x 5\n",
    "                input bbox\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            square bbox\n",
    "        \"\"\"\n",
    "        square_bbox = bbox.copy()\n",
    "\n",
    "        h = bbox[:, 3] - bbox[:, 1] + 1\n",
    "        w = bbox[:, 2] - bbox[:, 0] + 1\n",
    "        max_side = np.maximum(h,w)\n",
    "        square_bbox[:, 0] = bbox[:, 0] + w*0.5 - max_side*0.5\n",
    "        square_bbox[:, 1] = bbox[:, 1] + h*0.5 - max_side*0.5\n",
    "        square_bbox[:, 2] = square_bbox[:, 0] + max_side - 1\n",
    "        square_bbox[:, 3] = square_bbox[:, 1] + max_side - 1\n",
    "        return square_bbox\n",
    "\n",
    "    def calibrate_box(self, bbox, reg):\n",
    "        \"\"\"\n",
    "            calibrate bboxes\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "            bbox: numpy array, shape n x 5\n",
    "                input bboxes\n",
    "            reg:  numpy array, shape n x 4\n",
    "                bboxex adjustment\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            bboxes after refinement\n",
    "\n",
    "        \"\"\"\n",
    "        w = bbox[:, 2] - bbox[:, 0] + 1\n",
    "        w = np.expand_dims(w, 1)\n",
    "        h = bbox[:, 3] - bbox[:, 1] + 1\n",
    "        h = np.expand_dims(h, 1)\n",
    "        reg_m = np.hstack([w, h, w, h])\n",
    "        aug = reg_m * reg\n",
    "        bbox[:, 0:4] = bbox[:, 0:4] + aug\n",
    "        return bbox\n",
    "\n",
    " \n",
    "    def pad(self, bboxes, w, h):\n",
    "        \"\"\"\n",
    "            pad the the bboxes, alse restrict the size of it\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "            bboxes: numpy array, n x 5\n",
    "                input bboxes\n",
    "            w: float number\n",
    "                width of the input image\n",
    "            h: float number\n",
    "                height of the input image\n",
    "        Returns :\n",
    "        ------s\n",
    "            dy, dx : numpy array, n x 1\n",
    "                start point of the bbox in target image\n",
    "            edy, edx : numpy array, n x 1\n",
    "                end point of the bbox in target image\n",
    "            y, x : numpy array, n x 1\n",
    "                start point of the bbox in original image\n",
    "            ex, ex : numpy array, n x 1\n",
    "                end point of the bbox in original image\n",
    "            tmph, tmpw: numpy array, n x 1\n",
    "                height and width of the bbox\n",
    "\n",
    "        \"\"\"\n",
    "        tmpw, tmph = bboxes[:, 2] - bboxes[:, 0] + 1,  bboxes[:, 3] - bboxes[:, 1] + 1\n",
    "        num_box = bboxes.shape[0]\n",
    "\n",
    "        dx , dy= np.zeros((num_box, )), np.zeros((num_box, ))\n",
    "        edx, edy  = tmpw.copy()-1, tmph.copy()-1\n",
    "\n",
    "        x, y, ex, ey = bboxes[:, 0], bboxes[:, 1], bboxes[:, 2], bboxes[:, 3]\n",
    "\n",
    "        tmp_index = np.where(ex > w-1)\n",
    "        edx[tmp_index] = tmpw[tmp_index] + w - 2 - ex[tmp_index]\n",
    "        ex[tmp_index] = w - 1\n",
    "\n",
    "        tmp_index = np.where(ey > h-1)\n",
    "        edy[tmp_index] = tmph[tmp_index] + h - 2 - ey[tmp_index]\n",
    "        ey[tmp_index] = h - 1\n",
    "\n",
    "        tmp_index = np.where(x < 0)\n",
    "        dx[tmp_index] = 0 - x[tmp_index]\n",
    "        x[tmp_index] = 0\n",
    "\n",
    "        tmp_index = np.where(y < 0)\n",
    "        dy[tmp_index] = 0 - y[tmp_index]\n",
    "        y[tmp_index] = 0\n",
    "\n",
    "        return_list = [dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph]\n",
    "        return_list = [item.astype(np.int32) for item in return_list]\n",
    "\n",
    "        return  return_list\n",
    "\n",
    "    def slice_index(self, number):\n",
    "        \"\"\"\n",
    "            slice the index into (n,n,m), m < n\n",
    "        Parameters:\n",
    "        ----------\n",
    "            number: int number\n",
    "                number\n",
    "        \"\"\"\n",
    "        def chunks(l, n):\n",
    "            \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "            for i in range(0, len(l), n):\n",
    "                yield l[i:i + n]\n",
    "        num_list = range(number)\n",
    "        return list(chunks(num_list, self.num_worker))\n",
    "        \n",
    "    def detect_face_limited(self, img, det_type=2):\n",
    "        height, width, _ = img.shape\n",
    "        if det_type>=2:\n",
    "          total_boxes = np.array( [ [0.0, 0.0, img.shape[1], img.shape[0], 0.9] ] ,dtype=np.float32)\n",
    "          num_box = total_boxes.shape[0]\n",
    "\n",
    "          # pad the bbox\n",
    "          [dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph] = self.pad(total_boxes, width, height)\n",
    "          # (3, 24, 24) is the input shape for RNet\n",
    "          input_buf = np.zeros((num_box, 3, 24, 24), dtype=np.float32)\n",
    "\n",
    "          for i in range(num_box):\n",
    "              tmp = np.zeros((tmph[i], tmpw[i], 3), dtype=np.uint8)\n",
    "              tmp[dy[i]:edy[i]+1, dx[i]:edx[i]+1, :] = img[y[i]:ey[i]+1, x[i]:ex[i]+1, :]\n",
    "              input_buf[i, :, :, :] = adjust_input(cv2.resize(tmp, (24, 24)))\n",
    "\n",
    "          output = self.RNet.predict(input_buf)\n",
    "\n",
    "          # filter the total_boxes with threshold\n",
    "          passed = np.where(output[1][:, 1] > self.threshold[1])\n",
    "          total_boxes = total_boxes[passed]\n",
    "\n",
    "          if total_boxes.size == 0:\n",
    "              return None\n",
    "\n",
    "          total_boxes[:, 4] = output[1][passed, 1].reshape((-1,))\n",
    "          reg = output[0][passed]\n",
    "\n",
    "          # nms\n",
    "          pick = nms(total_boxes, 0.7, 'Union')\n",
    "          total_boxes = total_boxes[pick]\n",
    "          total_boxes = self.calibrate_box(total_boxes, reg[pick])\n",
    "          total_boxes = self.convert_to_square(total_boxes)\n",
    "          total_boxes[:, 0:4] = np.round(total_boxes[:, 0:4])\n",
    "        else:\n",
    "          total_boxes = np.array( [ [0.0, 0.0, img.shape[1], img.shape[0], 0.9] ] ,dtype=np.float32)\n",
    "        num_box = total_boxes.shape[0]\n",
    "        [dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph] = self.pad(total_boxes, width, height)\n",
    "        # (3, 48, 48) is the input shape for ONet\n",
    "        input_buf = np.zeros((num_box, 3, 48, 48), dtype=np.float32)\n",
    "\n",
    "        for i in range(num_box):\n",
    "            tmp = np.zeros((tmph[i], tmpw[i], 3), dtype=np.float32)\n",
    "            tmp[dy[i]:edy[i]+1, dx[i]:edx[i]+1, :] = img[y[i]:ey[i]+1, x[i]:ex[i]+1, :]\n",
    "            input_buf[i, :, :, :] = adjust_input(cv2.resize(tmp, (48, 48)))\n",
    "\n",
    "        output = self.ONet.predict(input_buf)\n",
    "        #print(output[2])\n",
    "\n",
    "        # filter the total_boxes with threshold\n",
    "        passed = np.where(output[2][:, 1] > self.threshold[2])\n",
    "        total_boxes = total_boxes[passed]\n",
    "\n",
    "        if total_boxes.size == 0:\n",
    "            return None\n",
    "\n",
    "        total_boxes[:, 4] = output[2][passed, 1].reshape((-1,))\n",
    "        reg = output[1][passed]\n",
    "        points = output[0][passed]\n",
    "\n",
    "        # compute landmark points\n",
    "        bbw = total_boxes[:, 2] - total_boxes[:, 0] + 1\n",
    "        bbh = total_boxes[:, 3] - total_boxes[:, 1] + 1\n",
    "        points[:, 0:5] = np.expand_dims(total_boxes[:, 0], 1) + np.expand_dims(bbw, 1) * points[:, 0:5]\n",
    "        points[:, 5:10] = np.expand_dims(total_boxes[:, 1], 1) + np.expand_dims(bbh, 1) * points[:, 5:10]\n",
    "\n",
    "        # nms\n",
    "        total_boxes = self.calibrate_box(total_boxes, reg)\n",
    "        pick = nms(total_boxes, 0.7, 'Min')\n",
    "        total_boxes = total_boxes[pick]\n",
    "        points = points[pick]\n",
    "        \n",
    "        if not self.accurate_landmark:\n",
    "            return total_boxes, points\n",
    "\n",
    "        #############################################\n",
    "        # extended stage\n",
    "        #############################################\n",
    "        num_box = total_boxes.shape[0]\n",
    "        patchw = np.maximum(total_boxes[:, 2]-total_boxes[:, 0]+1, total_boxes[:, 3]-total_boxes[:, 1]+1)\n",
    "        patchw = np.round(patchw*0.25)\n",
    "\n",
    "        # make it even\n",
    "        patchw[np.where(np.mod(patchw,2) == 1)] += 1\n",
    "\n",
    "        input_buf = np.zeros((num_box, 15, 24, 24), dtype=np.float32)\n",
    "        for i in range(5):\n",
    "            x, y = points[:, i], points[:, i+5]\n",
    "            x, y = np.round(x-0.5*patchw), np.round(y-0.5*patchw)\n",
    "            [dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph] = self.pad(np.vstack([x, y, x+patchw-1, y+patchw-1]).T,\n",
    "                                                                    width,\n",
    "                                                                    height)\n",
    "            for j in range(num_box):\n",
    "                tmpim = np.zeros((tmpw[j], tmpw[j], 3), dtype=np.float32)\n",
    "                tmpim[dy[j]:edy[j]+1, dx[j]:edx[j]+1, :] = img[y[j]:ey[j]+1, x[j]:ex[j]+1, :]\n",
    "                input_buf[j, i*3:i*3+3, :, :] = adjust_input(cv2.resize(tmpim, (24, 24)))\n",
    "\n",
    "        output = self.LNet.predict(input_buf)\n",
    "\n",
    "        pointx = np.zeros((num_box, 5))\n",
    "        pointy = np.zeros((num_box, 5))\n",
    "\n",
    "        for k in range(5):\n",
    "            # do not make a large movement\n",
    "            tmp_index = np.where(np.abs(output[k]-0.5) > 0.35)\n",
    "            output[k][tmp_index[0]] = 0.5\n",
    "\n",
    "            pointx[:, k] = np.round(points[:, k] - 0.5*patchw) + output[k][:, 0]*patchw\n",
    "            pointy[:, k] = np.round(points[:, k+5] - 0.5*patchw) + output[k][:, 1]*patchw\n",
    "\n",
    "        points = np.hstack([pointx, pointy])\n",
    "        points = points.astype(np.int32)\n",
    "\n",
    "        return total_boxes, points\n",
    "\n",
    "    def detect_face(self, img, det_type=0):\n",
    "        \"\"\"\n",
    "            detect face over img\n",
    "        Parameters:\n",
    "        ----------\n",
    "            img: numpy array, bgr order of shape (1, 3, n, m)\n",
    "                input image\n",
    "        Retures:\n",
    "        -------\n",
    "            bboxes: numpy array, n x 5 (x1,y2,x2,y2,score)\n",
    "                bboxes\n",
    "            points: numpy array, n x 10 (x1, x2 ... x5, y1, y2 ..y5)\n",
    "                landmarks\n",
    "        \"\"\"\n",
    "\n",
    "        # check input\n",
    "        height, width, _ = img.shape\n",
    "        if det_type==0:\n",
    "            MIN_DET_SIZE = 12\n",
    "\n",
    "            if img is None:\n",
    "                return None\n",
    "\n",
    "            # only works for color image\n",
    "            if len(img.shape) != 3:\n",
    "                return None\n",
    "\n",
    "            # detected boxes\n",
    "            total_boxes = []\n",
    "\n",
    "            minl = min( height, width)\n",
    "\n",
    "            # get all the valid scales\n",
    "            scales = []\n",
    "            m = MIN_DET_SIZE/self.minsize\n",
    "            minl *= m\n",
    "            factor_count = 0\n",
    "            while minl > MIN_DET_SIZE:\n",
    "                scales.append(m*self.factor**factor_count)\n",
    "                minl *= self.factor\n",
    "                factor_count += 1\n",
    "\n",
    "            #############################################\n",
    "            # first stage\n",
    "            #############################################\n",
    "            #for scale in scales:\n",
    "            #    return_boxes = self.detect_first_stage(img, scale, 0)\n",
    "            #    if return_boxes is not None:\n",
    "            #        total_boxes.append(return_boxes)\n",
    "            \n",
    "            sliced_index = self.slice_index(len(scales))\n",
    "            total_boxes = []\n",
    "            for batch in sliced_index:\n",
    "                #local_boxes = self.Pool.map( detect_first_stage_warpper, \\\n",
    "                #        izip(repeat(img), self.PNets[:len(batch)], [scales[i] for i in batch], repeat(self.threshold[0])) )\n",
    "                local_boxes = map( detect_first_stage_warpper, \\\n",
    "                        izip(repeat(img), self.PNets[:len(batch)], [scales[i] for i in batch], repeat(self.threshold[0])) )\n",
    "                total_boxes.extend(local_boxes)\n",
    "            \n",
    "            # remove the Nones \n",
    "            total_boxes = [ i for i in total_boxes if i is not None]\n",
    "\n",
    "            if len(total_boxes) == 0:\n",
    "                return None\n",
    "            \n",
    "            total_boxes = np.vstack(total_boxes)\n",
    "\n",
    "            if total_boxes.size == 0:\n",
    "                return None\n",
    "\n",
    "            # merge the detection from first stage\n",
    "            pick = nms(total_boxes[:, 0:5], 0.7, 'Union')\n",
    "            total_boxes = total_boxes[pick]\n",
    "\n",
    "            bbw = total_boxes[:, 2] - total_boxes[:, 0] + 1\n",
    "            bbh = total_boxes[:, 3] - total_boxes[:, 1] + 1\n",
    "\n",
    "            # refine the bboxes\n",
    "            total_boxes = np.vstack([total_boxes[:, 0]+total_boxes[:, 5] * bbw,\n",
    "                                     total_boxes[:, 1]+total_boxes[:, 6] * bbh,\n",
    "                                     total_boxes[:, 2]+total_boxes[:, 7] * bbw,\n",
    "                                     total_boxes[:, 3]+total_boxes[:, 8] * bbh,\n",
    "                                     total_boxes[:, 4]\n",
    "                                     ])\n",
    "\n",
    "            total_boxes = total_boxes.T\n",
    "            total_boxes = self.convert_to_square(total_boxes)\n",
    "            total_boxes[:, 0:4] = np.round(total_boxes[:, 0:4])\n",
    "        else:\n",
    "            total_boxes = np.array( [ [0.0, 0.0, img.shape[1], img.shape[0], 0.9] ] ,dtype=np.float32)\n",
    "\n",
    "        #############################################\n",
    "        # second stage\n",
    "        #############################################\n",
    "        num_box = total_boxes.shape[0]\n",
    "\n",
    "        # pad the bbox\n",
    "        [dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph] = self.pad(total_boxes, width, height)\n",
    "        # (3, 24, 24) is the input shape for RNet\n",
    "        input_buf = np.zeros((num_box, 3, 24, 24), dtype=np.float32)\n",
    "\n",
    "        for i in range(num_box):\n",
    "            tmp = np.zeros((tmph[i], tmpw[i], 3), dtype=np.uint8)\n",
    "            tmp[dy[i]:edy[i]+1, dx[i]:edx[i]+1, :] = img[y[i]:ey[i]+1, x[i]:ex[i]+1, :]\n",
    "            input_buf[i, :, :, :] = adjust_input(cv2.resize(tmp, (24, 24)))\n",
    "\n",
    "        output = self.RNet.predict(input_buf)\n",
    "\n",
    "        # filter the total_boxes with threshold\n",
    "        passed = np.where(output[1][:, 1] > self.threshold[1])\n",
    "        total_boxes = total_boxes[passed]\n",
    "\n",
    "        if total_boxes.size == 0:\n",
    "            return None\n",
    "\n",
    "        total_boxes[:, 4] = output[1][passed, 1].reshape((-1,))\n",
    "        reg = output[0][passed]\n",
    "\n",
    "        # nms\n",
    "        pick = nms(total_boxes, 0.7, 'Union')\n",
    "        total_boxes = total_boxes[pick]\n",
    "        total_boxes = self.calibrate_box(total_boxes, reg[pick])\n",
    "        total_boxes = self.convert_to_square(total_boxes)\n",
    "        total_boxes[:, 0:4] = np.round(total_boxes[:, 0:4])\n",
    "\n",
    "        #############################################\n",
    "        # third stage\n",
    "        #############################################\n",
    "        num_box = total_boxes.shape[0]\n",
    "\n",
    "        # pad the bbox\n",
    "        [dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph] = self.pad(total_boxes, width, height)\n",
    "        # (3, 48, 48) is the input shape for ONet\n",
    "        input_buf = np.zeros((num_box, 3, 48, 48), dtype=np.float32)\n",
    "\n",
    "        for i in range(num_box):\n",
    "            tmp = np.zeros((tmph[i], tmpw[i], 3), dtype=np.float32)\n",
    "            tmp[dy[i]:edy[i]+1, dx[i]:edx[i]+1, :] = img[y[i]:ey[i]+1, x[i]:ex[i]+1, :]\n",
    "            input_buf[i, :, :, :] = adjust_input(cv2.resize(tmp, (48, 48)))\n",
    "\n",
    "        output = self.ONet.predict(input_buf)\n",
    "\n",
    "        # filter the total_boxes with threshold\n",
    "        passed = np.where(output[2][:, 1] > self.threshold[2])\n",
    "        total_boxes = total_boxes[passed]\n",
    "\n",
    "        if total_boxes.size == 0:\n",
    "            return None\n",
    "\n",
    "        total_boxes[:, 4] = output[2][passed, 1].reshape((-1,))\n",
    "        reg = output[1][passed]\n",
    "        points = output[0][passed]\n",
    "\n",
    "        # compute landmark points\n",
    "        bbw = total_boxes[:, 2] - total_boxes[:, 0] + 1\n",
    "        bbh = total_boxes[:, 3] - total_boxes[:, 1] + 1\n",
    "        points[:, 0:5] = np.expand_dims(total_boxes[:, 0], 1) + np.expand_dims(bbw, 1) * points[:, 0:5]\n",
    "        points[:, 5:10] = np.expand_dims(total_boxes[:, 1], 1) + np.expand_dims(bbh, 1) * points[:, 5:10]\n",
    "\n",
    "        # nms\n",
    "        total_boxes = self.calibrate_box(total_boxes, reg)\n",
    "        pick = nms(total_boxes, 0.7, 'Min')\n",
    "        total_boxes = total_boxes[pick]\n",
    "        points = points[pick]\n",
    "        \n",
    "        if not self.accurate_landmark:\n",
    "            return total_boxes, points\n",
    "\n",
    "        #############################################\n",
    "        # extended stage\n",
    "        #############################################\n",
    "        num_box = total_boxes.shape[0]\n",
    "        patchw = np.maximum(total_boxes[:, 2]-total_boxes[:, 0]+1, total_boxes[:, 3]-total_boxes[:, 1]+1)\n",
    "        patchw = np.round(patchw*0.25)\n",
    "\n",
    "        # make it even\n",
    "        patchw[np.where(np.mod(patchw,2) == 1)] += 1\n",
    "\n",
    "        input_buf = np.zeros((num_box, 15, 24, 24), dtype=np.float32)\n",
    "        for i in range(5):\n",
    "            x, y = points[:, i], points[:, i+5]\n",
    "            x, y = np.round(x-0.5*patchw), np.round(y-0.5*patchw)\n",
    "            [dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph] = self.pad(np.vstack([x, y, x+patchw-1, y+patchw-1]).T,\n",
    "                                                                    width,\n",
    "                                                                    height)\n",
    "            for j in range(num_box):\n",
    "                tmpim = np.zeros((tmpw[j], tmpw[j], 3), dtype=np.float32)\n",
    "                tmpim[dy[j]:edy[j]+1, dx[j]:edx[j]+1, :] = img[y[j]:ey[j]+1, x[j]:ex[j]+1, :]\n",
    "                input_buf[j, i*3:i*3+3, :, :] = adjust_input(cv2.resize(tmpim, (24, 24)))\n",
    "\n",
    "        output = self.LNet.predict(input_buf)\n",
    "\n",
    "        pointx = np.zeros((num_box, 5))\n",
    "        pointy = np.zeros((num_box, 5))\n",
    "\n",
    "        for k in range(5):\n",
    "            # do not make a large movement\n",
    "            tmp_index = np.where(np.abs(output[k]-0.5) > 0.35)\n",
    "            output[k][tmp_index[0]] = 0.5\n",
    "\n",
    "            pointx[:, k] = np.round(points[:, k] - 0.5*patchw) + output[k][:, 0]*patchw\n",
    "            pointy[:, k] = np.round(points[:, k+5] - 0.5*patchw) + output[k][:, 1]*patchw\n",
    "\n",
    "        points = np.hstack([pointx, pointy])\n",
    "        points = points.astype(np.int32)\n",
    "\n",
    "        return total_boxes, points\n",
    "\n",
    "\n",
    "\n",
    "    def list2colmatrix(self, pts_list):\n",
    "        \"\"\"\n",
    "            convert list to column matrix\n",
    "        Parameters:\n",
    "        ----------\n",
    "            pts_list:\n",
    "                input list\n",
    "        Retures:\n",
    "        -------\n",
    "            colMat: \n",
    "\n",
    "        \"\"\"\n",
    "        assert len(pts_list) > 0\n",
    "        colMat = []\n",
    "        for i in range(len(pts_list)):\n",
    "            colMat.append(pts_list[i][0])\n",
    "            colMat.append(pts_list[i][1])\n",
    "        colMat = np.matrix(colMat).transpose()\n",
    "        return colMat\n",
    "\n",
    "    def find_tfrom_between_shapes(self, from_shape, to_shape):\n",
    "        \"\"\"\n",
    "            find transform between shapes\n",
    "        Parameters:\n",
    "        ----------\n",
    "            from_shape: \n",
    "            to_shape: \n",
    "        Retures:\n",
    "        -------\n",
    "            tran_m:\n",
    "            tran_b:\n",
    "        \"\"\"\n",
    "        assert from_shape.shape[0] == to_shape.shape[0] and from_shape.shape[0] % 2 == 0\n",
    "\n",
    "        sigma_from = 0.0\n",
    "        sigma_to = 0.0\n",
    "        cov = np.matrix([[0.0, 0.0], [0.0, 0.0]])\n",
    "\n",
    "        # compute the mean and cov\n",
    "        from_shape_points = from_shape.reshape(from_shape.shape[0]/2, 2)\n",
    "        to_shape_points = to_shape.reshape(to_shape.shape[0]/2, 2)\n",
    "        mean_from = from_shape_points.mean(axis=0)\n",
    "        mean_to = to_shape_points.mean(axis=0)\n",
    "\n",
    "        for i in range(from_shape_points.shape[0]):\n",
    "            temp_dis = np.linalg.norm(from_shape_points[i] - mean_from)\n",
    "            sigma_from += temp_dis * temp_dis\n",
    "            temp_dis = np.linalg.norm(to_shape_points[i] - mean_to)\n",
    "            sigma_to += temp_dis * temp_dis\n",
    "            cov += (to_shape_points[i].transpose() - mean_to.transpose()) * (from_shape_points[i] - mean_from)\n",
    "\n",
    "        sigma_from = sigma_from / to_shape_points.shape[0]\n",
    "        sigma_to = sigma_to / to_shape_points.shape[0]\n",
    "        cov = cov / to_shape_points.shape[0]\n",
    "\n",
    "        # compute the affine matrix\n",
    "        s = np.matrix([[1.0, 0.0], [0.0, 1.0]])\n",
    "        u, d, vt = np.linalg.svd(cov)\n",
    "\n",
    "        if np.linalg.det(cov) < 0:\n",
    "            if d[1] < d[0]:\n",
    "                s[1, 1] = -1\n",
    "            else:\n",
    "                s[0, 0] = -1\n",
    "        r = u * s * vt\n",
    "        c = 1.0\n",
    "        if sigma_from != 0:\n",
    "            c = 1.0 / sigma_from * np.trace(np.diag(d) * s)\n",
    "\n",
    "        tran_b = mean_to.transpose() - c * r * mean_from.transpose()\n",
    "        tran_m = c * r\n",
    "\n",
    "        return tran_m, tran_b\n",
    "\n",
    "    def extract_image_chips(self, img, points, desired_size=256, padding=0):\n",
    "        \"\"\"\n",
    "            crop and align face\n",
    "        Parameters:\n",
    "        ----------\n",
    "            img: numpy array, bgr order of shape (1, 3, n, m)\n",
    "                input image\n",
    "            points: numpy array, n x 10 (x1, x2 ... x5, y1, y2 ..y5)\n",
    "            desired_size: default 256\n",
    "            padding: default 0\n",
    "        Retures:\n",
    "        -------\n",
    "            crop_imgs: list, n\n",
    "                cropped and aligned faces \n",
    "        \"\"\"\n",
    "        crop_imgs = []\n",
    "        for p in points:\n",
    "            shape  =[]\n",
    "            for k in range(len(p)/2):\n",
    "                shape.append(p[k])\n",
    "                shape.append(p[k+5])\n",
    "\n",
    "            if padding > 0:\n",
    "                padding = padding\n",
    "            else:\n",
    "                padding = 0\n",
    "            # average positions of face points\n",
    "            mean_face_shape_x = [0.224152, 0.75610125, 0.490127, 0.254149, 0.726104]\n",
    "            mean_face_shape_y = [0.2119465, 0.2119465, 0.628106, 0.780233, 0.780233]\n",
    "\n",
    "            from_points = []\n",
    "            to_points = []\n",
    "\n",
    "            for i in range(len(shape)/2):\n",
    "                x = (padding + mean_face_shape_x[i]) / (2 * padding + 1) * desired_size\n",
    "                y = (padding + mean_face_shape_y[i]) / (2 * padding + 1) * desired_size\n",
    "                to_points.append([x, y])\n",
    "                from_points.append([shape[2*i], shape[2*i+1]])\n",
    "\n",
    "            # convert the points to Mat\n",
    "            from_mat = self.list2colmatrix(from_points)\n",
    "            to_mat = self.list2colmatrix(to_points)\n",
    "\n",
    "            # compute the similar transfrom\n",
    "            tran_m, tran_b = self.find_tfrom_between_shapes(from_mat, to_mat)\n",
    "\n",
    "            probe_vec = np.matrix([1.0, 0.0]).transpose()\n",
    "            probe_vec = tran_m * probe_vec\n",
    "\n",
    "            scale = np.linalg.norm(probe_vec)\n",
    "            angle = 180.0 / math.pi * math.atan2(probe_vec[1, 0], probe_vec[0, 0])\n",
    "\n",
    "            from_center = [(shape[0]+shape[2])/2.0, (shape[1]+shape[3])/2.0]\n",
    "            to_center = [0, 0]\n",
    "            to_center[1] = desired_size * 0.4\n",
    "            to_center[0] = desired_size * 0.5\n",
    "\n",
    "            ex = to_center[0] - from_center[0]\n",
    "            ey = to_center[1] - from_center[1]\n",
    "\n",
    "            rot_mat = cv2.getRotationMatrix2D((from_center[0], from_center[1]), -1*angle, scale)\n",
    "            rot_mat[0][2] += ex\n",
    "            rot_mat[1][2] += ey\n",
    "\n",
    "            chips = cv2.warpAffine(img, rot_mat, (desired_size, desired_size))\n",
    "            crop_imgs.append(chips)\n",
    "\n",
    "        return crop_imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper \n",
    "Helper functions for SERFIQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "\n",
    "def nms(boxes, overlap_threshold, mode='Union'):\n",
    "    \"\"\"\n",
    "        non max suppression\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "        box: numpy array n x 5\n",
    "            input bbox array\n",
    "        overlap_threshold: float number\n",
    "            threshold of overlap\n",
    "        mode: float number\n",
    "            how to compute overlap ratio, 'Union' or 'Min'\n",
    "    Returns:\n",
    "    -------\n",
    "        index array of the selected bbox\n",
    "    \"\"\"\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # if the bounding boxes integers, convert them to floats\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1, y1, x2, y2, score = [boxes[:, i] for i in range(5)]\n",
    "\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(score)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        inter = w * h\n",
    "        if mode == 'Min':\n",
    "            overlap = inter / np.minimum(area[i], area[idxs[:last]])\n",
    "        else:\n",
    "            overlap = inter / (area[i] + area[idxs[:last]] - inter)\n",
    "\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "                                               np.where(overlap > overlap_threshold)[0])))\n",
    "\n",
    "    return pick\n",
    "\n",
    "def adjust_input(in_data):\n",
    "    \"\"\"\n",
    "        adjust the input from (h, w, c) to ( 1, c, h, w) for network input\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "        in_data: numpy array of shape (h, w, c)\n",
    "            input data\n",
    "    Returns:\n",
    "    -------\n",
    "        out_data: numpy array of shape (1, c, h, w)\n",
    "            reshaped array\n",
    "    \"\"\"\n",
    "    if in_data.dtype is not np.dtype('float32'):\n",
    "        out_data = in_data.astype(np.float32)\n",
    "    else:\n",
    "        out_data = in_data\n",
    "\n",
    "    out_data = out_data.transpose((2,0,1))\n",
    "    out_data = np.expand_dims(out_data, 0)\n",
    "    out_data = (out_data - 127.5)*0.0078125\n",
    "    return out_data\n",
    "\n",
    "def generate_bbox(map, reg, scale, threshold):\n",
    "     \"\"\"\n",
    "         generate bbox from feature map\n",
    "     Parameters:\n",
    "     ----------\n",
    "         map: numpy array , n x m x 1\n",
    "             detect score for each position\n",
    "         reg: numpy array , n x m x 4\n",
    "             bbox\n",
    "         scale: float number\n",
    "             scale of this detection\n",
    "         threshold: float number\n",
    "             detect threshold\n",
    "     Returns:\n",
    "     -------\n",
    "         bbox array\n",
    "     \"\"\"\n",
    "     stride = 2\n",
    "     cellsize = 12\n",
    "\n",
    "     t_index = np.where(map>threshold)\n",
    "\n",
    "     # find nothing\n",
    "     if t_index[0].size == 0:\n",
    "         return np.array([])\n",
    "\n",
    "     dx1, dy1, dx2, dy2 = [reg[0, i, t_index[0], t_index[1]] for i in range(4)]\n",
    "\n",
    "     reg = np.array([dx1, dy1, dx2, dy2])\n",
    "     score = map[t_index[0], t_index[1]]\n",
    "     boundingbox = np.vstack([np.round((stride*t_index[1]+1)/scale),\n",
    "                              np.round((stride*t_index[0]+1)/scale),\n",
    "                              np.round((stride*t_index[1]+1+cellsize)/scale),\n",
    "                              np.round((stride*t_index[0]+1+cellsize)/scale),\n",
    "                              score,\n",
    "                              reg])\n",
    "\n",
    "     return boundingbox.T\n",
    "\n",
    "\n",
    "def detect_first_stage(img, net, scale, threshold):\n",
    "    \"\"\"\n",
    "        run PNet for first stage\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "        img: numpy array, bgr order\n",
    "            input image\n",
    "        scale: float number\n",
    "            how much should the input image scale\n",
    "        net: PNet\n",
    "            worker\n",
    "    Returns:\n",
    "    -------\n",
    "        total_boxes : bboxes\n",
    "    \"\"\"\n",
    "    height, width, _ = img.shape\n",
    "    hs = int(math.ceil(height * scale))\n",
    "    ws = int(math.ceil(width * scale))\n",
    "    \n",
    "    im_data = cv2.resize(img, (ws,hs))\n",
    "    \n",
    "    # adjust for the network input\n",
    "    input_buf = adjust_input(im_data)\n",
    "    output = net.predict(input_buf)\n",
    "    boxes = generate_bbox(output[1][0,1,:,:], output[0], scale, threshold)\n",
    "\n",
    "    if boxes.size == 0:\n",
    "        return None\n",
    "\n",
    "    # nms\n",
    "    pick = nms(boxes[:,0:5], 0.5, mode='Union')\n",
    "    boxes = boxes[pick]\n",
    "    return boxes\n",
    "\n",
    "def detect_first_stage_warpper( args ):\n",
    "    return detect_first_stage(*args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SER-FIQ \n",
    "SER-FIQ class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SER_FIQ:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 gpu:int=0, # Which gpu should be used -> gpu id\n",
    "                 det:int=0, # Mtcnn option, 1= Use R+O, 0=Detect from beginning\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Reimplementing Insightface's FaceModel class.\n",
    "        Now the dropout output and the network output are returned after a forward pass.\n",
    "        Parameters\n",
    "        ----------\n",
    "        gpu : int, optional\n",
    "            The GPU to be used by Mxnet. The default is 0.\n",
    "            If set to None, CPU is used instead.\n",
    "        det : int, optional\n",
    "            Mtcnn option, 1= Use R+0, 0= Detect from beginning. The default is 0.\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "        \"\"\"\n",
    "        \n",
    "        if gpu is None:\n",
    "            self.device = mx.cpu()\n",
    "        else:\n",
    "            self.device = mx.gpu(gpu)\n",
    "\n",
    "        self.insightface = gluon.nn.SymbolBlock.imports(\n",
    "                                    \"./models/insightface/model/insightface-symbol.json\",\n",
    "                                    ['data'],\n",
    "                                    \"./models/insightface/model/insightface-0000.params\", \n",
    "                                    ctx=self.device\n",
    "                           )\n",
    "\n",
    "        \n",
    "        self.det_minsize = 50\n",
    "        self.det_threshold = [0.6,0.7,0.8]\n",
    "        self.det = det\n",
    "        \n",
    "        self.preprocess = preprocess\n",
    "        \n",
    "        thrs = self.det_threshold if det==0 else [0.0,0.0,0.2]\n",
    "        \n",
    "        self.detector = MtcnnDetector(model_folder=\"./models/insightface/mtcnn-model/\", \n",
    "                                                    ctx=self.device, \n",
    "                                                    num_worker=1, \n",
    "                                                    accurate_landmark = True, \n",
    "                                                    threshold=thrs\n",
    "                                                    )\n",
    "        \n",
    "    def apply_mtcnn(self, face_image : np.ndarray):\n",
    "        \"\"\"\n",
    "        Applies MTCNN Detector on the given face image and returns\n",
    "        the cropped image.\n",
    "        \n",
    "        If no face could be detected None is returned.\n",
    "        Parameters\n",
    "        ----------\n",
    "        face_image : np.ndarray\n",
    "            Face imaged loaded via OpenCV.\n",
    "        Returns\n",
    "        -------\n",
    "        Face Image : np.ndarray, shape (3,112,112).\n",
    "        None, if no face could be detected\n",
    "        \"\"\"\n",
    "        detected = self.detector.detect_face(face_image, det_type=self.det)\n",
    "        \n",
    "        if detected is None:\n",
    "            return None\n",
    "        \n",
    "        bbox, points = detected\n",
    "        \n",
    "        if bbox.shape[0] == 0:\n",
    "            return None\n",
    "\n",
    "        points = points[0, :].reshape((2,5)).T\n",
    "        \n",
    "        image = self.preprocess(face_image, bbox, points, image_size=\"112,112\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        return np.transpose(image, (2,0,1))\n",
    "    \n",
    "      \n",
    "     \n",
    "    def get_score(self, aligned_img : np.ndarray, \n",
    "                        T : int = 100,\n",
    "                        alpha : float = 130.0,\n",
    "                        r : float = 0.88):\n",
    "        \"\"\"\n",
    "        Calculates the SER-FIQ score for a given aligned image using T passes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        aligned_img : np.ndarray, shape (3, h, w)\n",
    "            Aligned face image, in RGB format.\n",
    "        T : int, optional\n",
    "            Amount of forward passes to use. The default is 100.\n",
    "        alpha : float, optional\n",
    "            Stretching factor, can be choosen to scale the score values\n",
    "        r : float, optional\n",
    "            Score displacement\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        SER-FIQ score : float.\n",
    "        \"\"\"\n",
    "        # Color Channel is not the first dimension, swap dims.\n",
    "        if aligned_img.shape[0] != 3:\n",
    "            aligned_img = np.transpose(aligned_img, (2,0,1))\n",
    "\n",
    "        input_blob = np.expand_dims(aligned_img, axis=0)\n",
    "        repeated = np.repeat(input_blob, T, axis=0)\n",
    "        gpu_repeated = mx.nd.array(repeated, ctx=self.device)\n",
    "\n",
    "        X = self.insightface(gpu_repeated).asnumpy()\n",
    "               \n",
    "        norm = normalize(X, axis=1)\n",
    "        \n",
    "        # Only get the upper triangle of the distance matrix\n",
    "        eucl_dist = euclidean_distances(norm, norm)[np.triu_indices(T, k=1)]\n",
    "       \n",
    "        # Calculate score as given in the paper\n",
    "        score = 2*(1/(1+np.exp(np.mean(eucl_dist))))\n",
    "        # Normalize value based on alpha and r\n",
    "        return 1 / (1+np.exp(-(alpha * (score - r))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SERFIQ\n",
    "Get SERFIQ model for main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_serfiq_model():\n",
    "    # gpu_available = False\n",
    "    # gpu_available = bool(tf.config.list_physical_devices('GPU'))\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    if gpu_available:\n",
    "        serfiq = SER_FIQ(gpu=0)\n",
    "    elif not gpu_available:\n",
    "        serfiq = SER_FIQ(gpu=None)\n",
    "    else:\n",
    "        raise ValueError(f\"Value of GPU: {gpu_available} not valid\")\n",
    "    \n",
    "    return serfiq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('sql-face')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a84f744ed89671113ba95f00e1aad6d21abade608318eb8af248311f249adcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
