{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SER-FIQ\n",
    "\n",
    "> Face Image Quality model from [Terhorst](https://github.com/pterhoer/FaceImageQuality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp serfiq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from insightface.src import mtcnn_detector\n",
    "from insightface.src import face_preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SER_FIQ:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 gpu:int=0, # Which gpu should be used -> gpu id\n",
    "                 det:int=0, # Mtcnn option, 1= Use R+O, 0=Detect from beginning\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Reimplementing Insightface's FaceModel class.\n",
    "        Now the dropout output and the network output are returned after a forward pass.\n",
    "        Parameters\n",
    "        ----------\n",
    "        gpu : int, optional\n",
    "            The GPU to be used by Mxnet. The default is 0.\n",
    "            If set to None, CPU is used instead.\n",
    "        det : int, optional\n",
    "            Mtcnn option, 1= Use R+0, 0= Detect from beginning. The default is 0.\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "        \"\"\"\n",
    "        \n",
    "        if gpu is None:\n",
    "            self.device = mx.cpu()\n",
    "        else:\n",
    "            self.device = mx.gpu(gpu)\n",
    "\n",
    "        self.insightface = gluon.nn.SymbolBlock.imports(\n",
    "                                    \"../insightface/model/insightface-symbol.json\",\n",
    "                                    ['data'],\n",
    "                                    \"../insightface/model/insightface-0000.params\", \n",
    "                                    ctx=self.device\n",
    "                           )\n",
    "\n",
    "        \n",
    "        self.det_minsize = 50\n",
    "        self.det_threshold = [0.6,0.7,0.8]\n",
    "        self.det = det\n",
    "        \n",
    "        self.preprocess = face_preprocess.preprocess\n",
    "        \n",
    "        thrs = self.det_threshold if det==0 else [0.0,0.0,0.2]\n",
    "        \n",
    "        self.detector = mtcnn_detector.MtcnnDetector(model_folder=\"../insightface/mtcnn-model/\", \n",
    "                                                    ctx=self.device, \n",
    "                                                    num_worker=1, \n",
    "                                                    accurate_landmark = True, \n",
    "                                                    threshold=thrs\n",
    "                                                    )\n",
    "        \n",
    "    def apply_mtcnn(self, face_image : np.ndarray):\n",
    "        \"\"\"\n",
    "        Applies MTCNN Detector on the given face image and returns\n",
    "        the cropped image.\n",
    "        \n",
    "        If no face could be detected None is returned.\n",
    "        Parameters\n",
    "        ----------\n",
    "        face_image : np.ndarray\n",
    "            Face imaged loaded via OpenCV.\n",
    "        Returns\n",
    "        -------\n",
    "        Face Image : np.ndarray, shape (3,112,112).\n",
    "        None, if no face could be detected\n",
    "        \"\"\"\n",
    "        detected = self.detector.detect_face(face_image, det_type=self.det)\n",
    "        \n",
    "        if detected is None:\n",
    "            return None\n",
    "        \n",
    "        bbox, points = detected\n",
    "        \n",
    "        if bbox.shape[0] == 0:\n",
    "            return None\n",
    "\n",
    "        points = points[0, :].reshape((2,5)).T\n",
    "        \n",
    "        image = self.preprocess(face_image, bbox, points, image_size=\"112,112\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        return np.transpose(image, (2,0,1))\n",
    "    \n",
    "      \n",
    "     \n",
    "    def get_score(self, aligned_img : np.ndarray, \n",
    "                        T : int = 100,\n",
    "                        alpha : float = 130.0,\n",
    "                        r : float = 0.88):\n",
    "        \"\"\"\n",
    "        Calculates the SER-FIQ score for a given aligned image using T passes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        aligned_img : np.ndarray, shape (3, h, w)\n",
    "            Aligned face image, in RGB format.\n",
    "        T : int, optional\n",
    "            Amount of forward passes to use. The default is 100.\n",
    "        alpha : float, optional\n",
    "            Stretching factor, can be choosen to scale the score values\n",
    "        r : float, optional\n",
    "            Score displacement\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        SER-FIQ score : float.\n",
    "        \"\"\"\n",
    "        # Color Channel is not the first dimension, swap dims.\n",
    "        if aligned_img.shape[0] != 3:\n",
    "            aligned_img = np.transpose(aligned_img, (2,0,1))\n",
    "\n",
    "        input_blob = np.expand_dims(aligned_img, axis=0)\n",
    "        repeated = np.repeat(input_blob, T, axis=0)\n",
    "        gpu_repeated = mx.nd.array(repeated, ctx=self.device)\n",
    "\n",
    "        X = self.insightface(gpu_repeated).asnumpy()\n",
    "               \n",
    "        norm = normalize(X, axis=1)\n",
    "        \n",
    "        # Only get the upper triangle of the distance matrix\n",
    "        eucl_dist = euclidean_distances(norm, norm)[np.triu_indices(T, k=1)]\n",
    "       \n",
    "        # Calculate score as given in the paper\n",
    "        score = 2*(1/(1+np.exp(np.mean(eucl_dist))))\n",
    "        # Normalize value based on alpha and r\n",
    "        return 1 / (1+np.exp(-(alpha * (score - r))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_serfiq_model():\n",
    "    gpu_available = bool(tf.config.list_physical_devices('GPU'))\n",
    "    if gpu_available:\n",
    "        serfiq = SER_FIQ(gpu=0)\n",
    "    else:\n",
    "        serfiq = SER_FIQ(gpu=None)\n",
    "    \n",
    "    return serfiq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('sql-face')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
