{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qmagface\n",
    "\n",
    "> Face Image Recognition model from [QMagFace](https://github.com/pterhoer/QMagFace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp qmagface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms\n",
    "from torch.utils import data\n",
    "from collections import namedtuple, OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IresNet\n",
    "\n",
    "Model imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "__all__ = ['iresnet18', 'iresnet34', 'iresnet50', 'iresnet100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "class IBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1):\n",
    "        super(IBasicBlock, self).__init__()\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError(\n",
    "                'BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\n",
    "                \"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes, eps=2e-05, momentum=0.9)\n",
    "        self.conv1 = conv3x3(inplanes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, eps=2e-05, momentum=0.9)\n",
    "        self.prelu = nn.PReLU(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn3 = nn.BatchNorm2d(planes, eps=2e-05, momentum=0.9)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.prelu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "class IResNet(nn.Module):\n",
    "    fc_scale = 7 * 7\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=512, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None):\n",
    "        super(IResNet, self).__init__()\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes, eps=2e-05, momentum=0.9)\n",
    "        self.prelu = nn.PReLU(self.inplanes)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(\n",
    "            512 * block.expansion, eps=2e-05, momentum=0.9)\n",
    "        self.dropout = nn.Dropout2d(p=0.4, inplace=True)\n",
    "        self.fc = nn.Linear(512 * block.expansion * self.fc_scale, num_classes)\n",
    "        self.features = nn.BatchNorm1d(num_classes, eps=2e-05, momentum=0.9)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, IBasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion,\n",
    "                               eps=2e-05, momentum=0.9),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.prelu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.features(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def _iresnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = IResNet(block, layers, **kwargs)\n",
    "    # if pretrained:\n",
    "    # state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "    #                                        progress=progress)\n",
    "    # model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "def iresnet18(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet18', IBasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
    "                    **kwargs)\n",
    "\n",
    "\n",
    "def iresnet34(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet34', IBasicBlock, [3, 4, 6, 3], pretrained, progress,\n",
    "                    **kwargs)\n",
    "\n",
    "\n",
    "def iresnet50(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet50', IBasicBlock, [3, 4, 14, 3], pretrained, progress,\n",
    "                    **kwargs)\n",
    "\n",
    "\n",
    "def iresnet100(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet100', IBasicBlock, [3, 13, 30, 3], pretrained, progress,\n",
    "                    **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MagFace\n",
    "Functions from magface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def load_features(args):\n",
    "    if args.arch == 'iresnet34':\n",
    "        features = iresnet34(\n",
    "            pretrained=False,\n",
    "            num_classes=args.embedding_size,\n",
    "        )\n",
    "    elif args.arch == 'iresnet18':\n",
    "        features = iresnet18(\n",
    "            pretrained=False,\n",
    "            num_classes=args.embedding_size,\n",
    "        )\n",
    "    elif args.arch == 'iresnet50':\n",
    "        features = iresnet50(\n",
    "            pretrained=False,\n",
    "            num_classes=args.embedding_size,\n",
    "        )\n",
    "    elif args.arch == 'iresnet100':\n",
    "        features = iresnet100(\n",
    "            pretrained=False,\n",
    "            num_classes=args.embedding_size,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def load_dict_inf(args, model):\n",
    "    if os.path.isfile(args.resume):\n",
    "        print('=> loading pth from {} ...'.format(args.resume))\n",
    "        if args.cpu_mode:\n",
    "            checkpoint = torch.load(args.resume, map_location=torch.device(\"cpu\"))\n",
    "        else:\n",
    "            checkpoint = torch.load(args.resume)\n",
    "        _state_dict = clean_dict_inf(model, checkpoint['state_dict'])\n",
    "        model_dict = model.state_dict()\n",
    "        model_dict.update(_state_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "        # delete to release more space\n",
    "        del checkpoint\n",
    "        del _state_dict\n",
    "    else:\n",
    "        sys.exit(\"=> No checkpoint found at '{}'\".format(args.resume))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def clean_dict_inf(model, state_dict):\n",
    "    _state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        # # assert k[0:1] == 'features.module.'\n",
    "        new_k = 'features.'+'.'.join(k.split('.')[2:])\n",
    "        if new_k in model.state_dict().keys() and \\\n",
    "           v.size() == model.state_dict()[new_k].size():\n",
    "            _state_dict[new_k] = v\n",
    "        # assert k[0:1] == 'module.features.'\n",
    "        new_kk = '.'.join(k.split('.')[1:])\n",
    "        if new_kk in model.state_dict().keys() and \\\n",
    "           v.size() == model.state_dict()[new_kk].size():\n",
    "            _state_dict[new_kk] = v\n",
    "    num_model = len(model.state_dict().keys())\n",
    "    num_ckpt = len(_state_dict.keys())\n",
    "    if num_model != num_ckpt:\n",
    "        sys.exit(\"=> Not all weights loaded, model params: {}, loaded params: {}\".format(\n",
    "            num_model, num_ckpt))\n",
    "    return _state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "class NetworkBuilder_inf(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(NetworkBuilder_inf, self).__init__()\n",
    "        self.features = load_features(args)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # add Fp, a pose feature\n",
    "        x = self.features(input)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def builder_inf(args):\n",
    "    model = NetworkBuilder_inf(args)\n",
    "    # Used to run inference\n",
    "    model = load_dict_inf(args, model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Add 2 to integer number'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| exporti\n",
    "\n",
    "# model_path = os.path.join('models', 'qmagface', 'magface_epoch_00025.pth')\n",
    "\n",
    "\n",
    "def get_model(model_path = os.path.join('models', 'qmagface', 'magface_epoch_00025.pth')):\n",
    "    Args = namedtuple('Args', ['arch', 'resume', 'embedding_size', 'cpu_mode'])\n",
    "    args = Args('iresnet100', model_path, 512, True)\n",
    "    model = builder_inf(args)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def compute_qmagface_embeddings(aligned_img:np.array, model)->np.array:    \n",
    "    trans = torchvision.transforms.ToTensor()\n",
    "    input_ = trans(img)\n",
    "    input_ = input_.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(input_).to('cpu')\n",
    "    return embedding.squeeze().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql-face",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
