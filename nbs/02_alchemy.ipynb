{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Alchemy\n",
    "\n",
    "> Alchemy related functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains functions related to SQL Alchemy, which is a Python library used for working with databases. The main functions in this module are create_engine, Session, and Base. create_engine is used to create a connection to a database, Session is used to start a session with the database, and Base is used to define the structure of a database table. These functions are used to create, read, update, and delete (CRUD) data in a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp alchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 11:39:42.615923: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-12 11:39:44.603742: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/andrea/anaconda3/envs/sql-face/lib/python3.8/site-packages/cv2/../../lib64:/home/andrea/Documents/cuda_software/cuda/lib64:/usr/local/cuda-11.2/lib64\n",
      "2023-05-12 11:39:44.604141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/andrea/anaconda3/envs/sql-face/lib/python3.8/site-packages/cv2/../../lib64:/home/andrea/Documents/cuda_software/cuda/lib64:/usr/local/cuda-11.2/lib64\n",
      "2023-05-12 11:39:44.604159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msql_face\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtface\u001b[39;00m \u001b[39mimport\u001b[39;00m get_network, compute_tf_quality\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msql_face\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mqmagface\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model, compute_qmagface_embeddings\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msql_face\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfaceangles\u001b[39;00m \u001b[39mimport\u001b[39;00m compute_pose, compute_angles\n",
      "File \u001b[0;32m~/PycharmProjects/sql-face/sql_face/faceangles.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmediapipe\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmediapipe\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m \u001b[39mimport\u001b[39;00m landmark_pb2\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m \u001b[39mimport\u001b[39;00m transform \u001b[39mas\u001b[39;00m trans\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "#| exporti\n",
    "import os\n",
    "\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sqlalchemy import create_engine, or_\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from deepface.commons import functions\n",
    "from deepface import DeepFace\n",
    "\n",
    "from sql_face.databases import FaceDataBase\n",
    "from sql_face.tables import Base, Image, Detector, CroppedImage, EmbeddingModel, FaceImage, QualityModel, QualityImage \n",
    "from sql_face.tables import Gender, Age, Race, Emotion\n",
    "from sql_face.tface import get_network, compute_tf_quality\n",
    "from sql_face.qmagface import load_model, compute_qmagface_embeddings\n",
    "from sql_face.faceangles import compute_pose, compute_angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect session\n",
    "Connect to SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_session(\n",
    "    output_dir:str, # Output directory\n",
    "    db_name:str, # .db file name\n",
    "                    ): # SQL alchemy session \n",
    "    db_path = os.path.join(output_dir,db_name+'.db')       \n",
    "    engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "    if not os.path.exists(db_path):\n",
    "        if not os.path.exists(output_dir):\n",
    "            print(f'Creating output directory at {output_dir}')\n",
    "            os.mkdir(output_dir)\n",
    "            \n",
    "        print(f'Creating Db file at {db_path}')        \n",
    "    \n",
    "    # If the database file exists, update the tables in Base\n",
    "    Base.metadata.create_all(engine, checkfirst=True)\n",
    "    Session = sessionmaker()\n",
    "    Session.configure(bind=engine)\n",
    "    session = Session()\n",
    "    return session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table creators \n",
    "The functions in this section are used to create tables in the database for storing information about face detectors, images, cropped images, and other data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "Detectors, embedding models, quality models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_objects(session, model_class, names):\n",
    "    existing_objects = {name for (name,)  in session.query(model_class.name).all()}\n",
    "    new_objects = [model_class(name=name) for name in names if name not in existing_objects]\n",
    "    session.bulk_save_objects(new_objects)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_detectors(session, #SQL alchemy session object\n",
    "                    detector_names: List[str] # List of detectors to add to the database.\n",
    "                    ):\n",
    "\n",
    "    create_objects(session, Detector, detector_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_embedding_models(session, #SQL alchemy session object\n",
    "                            embedding_model_names: List[str]): # List of detectors to add to the database.\n",
    "                            \n",
    "    create_objects(session, EmbeddingModel, embedding_model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def create_quality_models(session, #SQL alchemy session object\n",
    "                        quality_model_names: List[str]): # List of quality models to add to the database.\n",
    "    \n",
    "    create_objects(session, QualityModel, quality_model_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images\n",
    "\n",
    "CroppedImage, FaceImage, QualityImage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def fill_cropped_image_serfiq(cr_img: CroppedImage, # CroppedImage object to be filled with bounding box and landmarks information.\n",
    "                                input_dir, # Directory where the images are stored.\n",
    "                                ser_fiq): #SERFIQ model object.\n",
    "                                \n",
    "        image = cr_img.images.get_image(input_dir)\n",
    "        aligned_img = ser_fiq.apply_mtcnn(image)\n",
    "        if aligned_img is None:\n",
    "            cr_img.bounding_box = []\n",
    "            cr_img.landmarks = []\n",
    "            cr_img.face_detected = False\n",
    "        elif len(aligned_img) == 0:\n",
    "            cr_img.bounding_box = []\n",
    "            cr_img.landmarks = []\n",
    "            cr_img.face_detected = False\n",
    "        else:\n",
    "            bbox, points = ser_fiq.detector.detect_face(image)\n",
    "            cr_img.bounding_box = bbox[0].tolist()\n",
    "            cr_img.landmarks = points[0].tolist()\n",
    "            cr_img.face_detected = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def fill_cropped_image_general(cr_img: CroppedImage, input_dir, **kwargs):\n",
    "    image = cr_img.images.get_image(input_dir)      \n",
    "    \n",
    "    try:\n",
    "        img_cropped, bounding_box = functions.preprocess_face(img=image,\n",
    "                                                                detector_backend=cr_img.detectors.name,\n",
    "                                                                enforce_detection=True,\n",
    "                                                                return_region=True)\n",
    "        \n",
    "        cr_img.bounding_box = bounding_box\n",
    "        cr_img.face_detected = True\n",
    "\n",
    "    except ValueError:\n",
    "        cr_img.bounding_box = []\n",
    "        cr_img.face_detected = False\n",
    "        #todo: change warning if the image is a video(frame).\n",
    "        print(f'Face not found in {cr_img.images.path} with {cr_img.detectors.name}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def commit_objects(objects, session):\n",
    "    if objects:\n",
    "        session.bulk_save_objects(objects)\n",
    "        try:\n",
    "            session.commit()\n",
    "        except IntegrityError:\n",
    "            session.rollback()\n",
    "            raise IntegrityError(\"Could not commit the objects\")\n",
    "        objects = []\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_cropped_images(session, input_dir:str, serfiq=None):\n",
    "    all_detectors = session.query(Detector).all()\n",
    "\n",
    "    for det in all_detectors:\n",
    "        if det.name == 'mtcnn_serfiq':\n",
    "            fill_cropped_image = fill_cropped_image_serfiq\n",
    "        else:\n",
    "            fill_cropped_image = fill_cropped_image_general\n",
    "\n",
    "        subquery = session.query(CroppedImage.image_id).filter(CroppedImage.detectors == det)\n",
    "        images = session.query(Image).filter(Image.image_id.notin_(subquery)).all()\n",
    "\n",
    "        cropped_images = []\n",
    "        count = 0\n",
    "        for img in tqdm(images, desc=f'Creating CroppedImages for detector {det.name}'):\n",
    "            cropped_image = CroppedImage()\n",
    "            cropped_image.image_id = img.image_id\n",
    "            cropped_image.detector_id = det.detector_id\n",
    "            cropped_image.images = img\n",
    "            cropped_image.detectors = det\n",
    "            fill_cropped_image(cropped_image, input_dir, ser_fiq=serfiq)\n",
    "            cropped_images.append(cropped_image)\n",
    "            count += 1\n",
    "\n",
    "            if count % 100 == 0:\n",
    "                cropped_images = commit_objects(cropped_images, session)\n",
    "\n",
    "        cropped_images = commit_objects(cropped_images, session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_face_images(session):\n",
    "    all_embedding_models = session.query(EmbeddingModel).all()\n",
    "    for emb in tqdm(all_embedding_models, desc='Embedding models'):\n",
    "        subquery = session.query(FaceImage.croppedImage_id).filter(FaceImage.embeddingModels == emb)\n",
    "        cropped_images = session.query(CroppedImage).filter(CroppedImage.croppedImage_id.notin_(subquery), \n",
    "                                                            CroppedImage.face_detected == True).all()\n",
    "\n",
    "        face_images_to_add = []                                                                       \n",
    "        count = 0\n",
    "        for cr_img in tqdm(cropped_images, desc=f'Face images in {emb.name}'):\n",
    "            face_image = FaceImage(croppedImage_id=cr_img.croppedImage_id, embeddingModel_id=emb.embeddingModel_id)\n",
    "            face_images_to_add.append(face_image)\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                face_images_to_add = commit_objects(face_images_to_add, session)\n",
    "\n",
    "        face_images_to_add = commit_objects(face_images_to_add, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_quality_images(session):\n",
    "    all_quality_models = session.query(QualityModel).all()\n",
    "\n",
    "    for qua in tqdm(all_quality_models, desc='Quality models'):\n",
    "        subquery = session.query(QualityImage.faceImage_id).filter(QualityImage.qualityModels == qua)\n",
    "        face_images = session.query(FaceImage).filter(FaceImage.faceImage_id.notin_(subquery)).all()\n",
    "\n",
    "        qua_images = []\n",
    "        count = 0\n",
    "\n",
    "        for face_img in tqdm(face_images, desc=f'Quality images in {qua.name}'):\n",
    "            qua_image = QualityImage()\n",
    "            qua_image.faceImages = face_img\n",
    "            qua_image.qualityModels = qua\n",
    "            qua_image.faceImage_id = face_img.faceImage_id\n",
    "            qua_image.qualityModel_id = qua.qualityModel_id\n",
    "            qua_images.append(qua_image)\n",
    "            count += 1\n",
    "\n",
    "            if count % 100 == 0:\n",
    "                qua_images = commit_objects(qua_images, session)\n",
    "\n",
    "        qua_images = commit_objects(qua_images, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table attribute update\n",
    "Once the tables are created, functions to fill in the Image, CroppedImage, FaceImage and Qualityimage attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def commit_updates(session, updated_objects, model_class):\n",
    "    if updated_objects:\n",
    "        session.bulk_update_mappings(model_class, updated_objects)\n",
    "        session.flush()\n",
    "        session.commit()\n",
    "        updated_objects.clear()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Images\n",
    "Attributes associated to the Image class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_gender(session, input_dir: str, databases: List[FaceDataBase], force_update: bool = False):\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.gender == None)\n",
    "        all_img = (query.all())\n",
    "\n",
    "        updated_images = []\n",
    "        count = 0\n",
    "\n",
    "        for img in tqdm(all_img, desc='Update gender'):\n",
    "\n",
    "            try:\n",
    "                filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=['gender'],\n",
    "                                           enforce_detection=True, detector_backend='mediapipe')\n",
    "                img.gender = Gender(filters[\"gender\"])\n",
    "\n",
    "            except ValueError:\n",
    "                img.gender = None\n",
    "\n",
    "            updated_images.append({\"image_id\": img.image_id, \"gender\": img.gender})\n",
    "\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                commit_updates(session, updated_images, Image)\n",
    "\n",
    "        commit_updates(session, updated_images, Image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_age(session, input_dir: str, databases: List[FaceDataBase], force_update: bool = False):\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.age == None)\n",
    "        all_img = (query.all())\n",
    "\n",
    "        updated_images = []\n",
    "        count = 0\n",
    "\n",
    "        for img in tqdm(all_img, desc='Update age'):\n",
    "            try:\n",
    "                filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=['age'],\n",
    "                                           enforce_detection=True, detector_backend='mediapipe')\n",
    "                age = filters[\"age\"]\n",
    "                img.age_number = age\n",
    "                img.age = Age.age2enum(age)\n",
    "\n",
    "            except ValueError:\n",
    "                img.age = None\n",
    "                img.age_number = None\n",
    "\n",
    "            updated_images.append({\"image_id\": img.image_id, \"age_number\": img.age_number, \"age\": img.age})\n",
    "\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                commit_updates(session, updated_images, Image)\n",
    "\n",
    "        commit_updates(session, updated_images, Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_emotion(session, input_dir: str, databases: List[FaceDataBase], force_update: bool = False):\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.emotion == None)\n",
    "        all_img = (query.all())\n",
    "\n",
    "        updated_images = []\n",
    "        count = 0\n",
    "\n",
    "        for img in tqdm(all_img, desc='Update facial expression (emotion)'):\n",
    "\n",
    "            try:\n",
    "                filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=['emotion'],\n",
    "                                           enforce_detection=True, detector_backend='mediapipe')\n",
    "                emotions = filters[\"emotion\"]\n",
    "                prime_emotion = max(emotions, key=emotions.get)\n",
    "                img.emotion = Emotion(prime_emotion)\n",
    "            except ValueError:\n",
    "                img.emotion = None\n",
    "\n",
    "            updated_images.append({\"image_id\": img.image_id, \"emotion\": img.emotion})\n",
    "\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                commit_updates(session, updated_images, Image)\n",
    "\n",
    "        commit_updates(session, updated_images, Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_race(session, input_dir: str, databases: List[FaceDataBase], force_update: bool = False):\n",
    "     for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.race == None)\n",
    "        all_img = (query.all())\n",
    "\n",
    "        updated_images = []\n",
    "        count = 0\n",
    "\n",
    "        for img in tqdm(all_img, desc='Update race'):\n",
    "            try:\n",
    "                filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=['race'],\n",
    "                                           enforce_detection=True, detector_backend='mediapipe')\n",
    "                races = filters[\"race\"]\n",
    "                prime_race = max(races, key=races.get)\n",
    "                img.race = Race(prime_race)\n",
    "            except ValueError:\n",
    "                img.race = None\n",
    "\n",
    "            updated_images.append({\"image_id\": img.image_id, \"race\": img.race})\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                commit_updates(session, updated_images, Image)\n",
    "\n",
    "        commit_updates(session, updated_images, Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_angles(session, input_dir: str, databases: List[FaceDataBase], force_update: bool = False):\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(or_(Image.angle_roll == None, Image.angle_yaw == None, Image.angle_pitch == None))\n",
    "\n",
    "        all_images = query.all()\n",
    "        count = 0\n",
    "        updated_images = []\n",
    "\n",
    "        for img in tqdm(all_images, desc='Update angles'):\n",
    "            img_array = img.get_image(input_dir)\n",
    "            a_pitch, a_yaw, a_roll = compute_angles(img_array)\n",
    "\n",
    "            upd_img = {}\n",
    "            if a_roll:\n",
    "                upd_img['angle_roll'] = a_roll\n",
    "            if a_yaw:\n",
    "                upd_img['angle_yaw'] = a_yaw\n",
    "            if a_pitch:\n",
    "                upd_img['angle_pitch'] = a_pitch\n",
    "\n",
    "            if upd_img:\n",
    "                upd_img['image_id'] = img.image_id\n",
    "                updated_images.append(upd_img)\n",
    "\n",
    "                count += 1\n",
    "                if count % 100 == 0:\n",
    "                    commit_updates(session, updated_images, Image)\n",
    "\n",
    "        commit_updates(session, updated_images, Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_pose(session, input_dir: str, databases: List[FaceDataBase], force_update: bool = False):\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(or_(Image.roll == None, Image.yaw == None, Image.pitch == None))\n",
    "\n",
    "        all_images = query.all()\n",
    "        count = 0\n",
    "        updated_images = []\n",
    "\n",
    "        for img in tqdm(all_images, desc='Update pose'):\n",
    "            angles = (img.angle_pitch, img.angle_yaw, img.angle_roll)\n",
    "            pitch, yaw, roll = compute_pose(angles)\n",
    "\n",
    "            upd_img = {}\n",
    "            if roll:\n",
    "                if force_update or not img.roll:\n",
    "                    upd_img[\"roll\"] = roll\n",
    "            if yaw:\n",
    "                if force_update or not img.yaw:\n",
    "                    upd_img[\"yaw\"] = yaw\n",
    "            if pitch:\n",
    "                if force_update or not img.pitch:\n",
    "                    upd_img[\"pitch\"] = pitch\n",
    "\n",
    "            if upd_img:\n",
    "                upd_img['image_id'] = img.image_id\n",
    "                updated_images.append(upd_img)\n",
    "\n",
    "                count += 1\n",
    "                if count % 100 == 0:\n",
    "                    commit_updates(session, updated_images, Image)\n",
    "\n",
    "        commit_updates(session, updated_images, Image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_images(session, input_dir,\n",
    "                databases:List[FaceDataBase], \n",
    "                attributes: List[str], \n",
    "                force_update: bool = False\n",
    "                ):\n",
    "\n",
    "    update_functions = {\n",
    "        'gender': update_gender,\n",
    "        'age': update_age,\n",
    "        'emotion': update_emotion,\n",
    "        'race': update_race,\n",
    "        'angles': update_angles,\n",
    "        'pose': update_pose\n",
    "    }\n",
    "\n",
    "    for attribute in attributes:\n",
    "        if attribute in update_functions:\n",
    "            update_functions[attribute](session, input_dir, databases, force_update)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update CroppedImages\n",
    "Attributes associated to the CroppedImage class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_cropped_images(session, input_dir: str, force_update: bool = False, serfiq=None):\n",
    "    query = session.query(CroppedImage).join(Detector)\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(or_(CroppedImage.face_detected == None, CroppedImage.bounding_box == None))\n",
    "\n",
    "    query_serfiq = query.filter(Detector.name == 'mtcnn_serfiq')\n",
    "    query_general = query.filter(Detector.name != 'mtcnn_serfiq')\n",
    "\n",
    "    all_cr_img_serfiq = (query_serfiq.all())\n",
    "    all_cr_img_general = (query_general.all())\n",
    "\n",
    "    updated_images = []\n",
    "    count = 0\n",
    "\n",
    "    if all_cr_img_serfiq:\n",
    "        fill_cropped_image = fill_cropped_image_serfiq\n",
    "        for cr_img in tqdm(all_cr_img_serfiq, desc='Update cropped images serfiq'):\n",
    "            fill_cropped_image(cr_img, input_dir, ser_fiq=serfiq)\n",
    "            updated_images.append(cr_img)\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                commit_updates(session, updated_images, CroppedImage)\n",
    "                \n",
    "    # Perform remaining updates for the 'mtcnn_serfiq' loop\n",
    "    commit_updates(session, updated_images, CroppedImage)\n",
    "\n",
    "    # ser_fiq = None\n",
    "    fill_cropped_image = fill_cropped_image_general\n",
    "\n",
    "    for cr_img in tqdm(all_cr_img_general, desc='Update cropped images'):\n",
    "        fill_cropped_image(cr_img, input_dir, ser_fiq=serfiq)\n",
    "        updated_images.append(cr_img)\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            commit_updates(session, updated_images, CroppedImage)\n",
    "            \n",
    "    # Perform remaining updates for the 'other detectors' loop\n",
    "    commit_updates(session, updated_images, CroppedImage)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update FaceImages\n",
    "Attributes associated to the FaceImage class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_face_images(session, input_dir:str, force_update: bool = False, serfiq = None):\n",
    "    update_embeddings_deepface(session, input_dir, force_update, serfiq = serfiq)\n",
    "    update_embeddings_qmagface(session, input_dir, force_update, serfiq = serfiq)\n",
    "    update_embeddings_arcface(session, input_dir, force_update, serfiq = serfiq)\n",
    "# self.update_confusion_score(force_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_embeddings_deepface(session, input_dir:str, force_update: bool = False, serfiq = None):\n",
    "\n",
    "    # General case\n",
    "    query = session.query(FaceImage, EmbeddingModel, Detector, Image) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector) \\\n",
    "        .join(Image, Image.image_id ==CroppedImage.image_id) \\\n",
    "        .filter(EmbeddingModel.name.notin_(['FaceVACs','QMagFace','ArcFace_normalized']), Detector.name != 'mtcnn_serfiq', Detector.name != 'mediapipe')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings DeepFace general'):\n",
    "        embedding = DeepFace.represent(face_img.Image.get_image(input_dir), detector_backend=face_img.Detector.name,\n",
    "                                    model_name=face_img.EmbeddingModel.name, enforce_detection=True)\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            commit_updates(session, updated_face_images, FaceImage)\n",
    "\n",
    "    commit_updates(session, updated_face_images, FaceImage)\n",
    "\n",
    "    # Mtcnn-serfiq\n",
    "    query = session.query(FaceImage, EmbeddingModel, CroppedImage) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector)\\\n",
    "        .filter(EmbeddingModel.name.notin_(['FaceVACs','QMagFace','ArcFace_normalized', 'SFace']), Detector.name == 'mtcnn_serfiq', Detector.name != 'mediapipe')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings DeepFace mtcnn-serfiq'):\n",
    "        embedding = DeepFace.represent(face_img.CroppedImage.get_aligned_image(input_dir, ser_fiq = serfiq), detector_backend='skip',\n",
    "                                    model_name=face_img.EmbeddingModel.name, enforce_detection=False)\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            commit_updates(session, updated_face_images, FaceImage)\n",
    "\n",
    "    commit_updates(session, updated_face_images, FaceImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def update_embeddings_deepface_old(session, input_dir:str, force_update: bool = False, serfiq = None):\n",
    "\n",
    "    # General case\n",
    "    query = session.query(FaceImage, EmbeddingModel, Detector, Image) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector) \\\n",
    "        .join(Image, Image.image_id ==CroppedImage.image_id) \\\n",
    "        .filter(EmbeddingModel.name.notin_(['FaceVACs','QMagFace','ArcFace_normalized']), Detector.name != 'mtcnn_serfiq', Detector.name != 'mediapipe')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings DeepFace general'):\n",
    "        embedding = DeepFace.represent(face_img.Image.get_image(input_dir), detector_backend=face_img.Detector.name,\n",
    "                                    model_name=face_img.EmbeddingModel.name, enforce_detection=True)\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "                session.commit()\n",
    "                updated_face_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "    if updated_face_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "\n",
    "    # Mtcnn-serfiq\n",
    "    query = session.query(FaceImage, EmbeddingModel, CroppedImage) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector)\\\n",
    "        .filter(EmbeddingModel.name.notin_(['FaceVACs','QMagFace','ArcFace_normalized', 'SFace']), Detector.name == 'mtcnn_serfiq', Detector.name != 'mediapipe')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings DeepFace mtcnn-serfiq'):\n",
    "        embedding = DeepFace.represent(face_img.CroppedImage.get_aligned_image(input_dir, ser_fiq = serfiq), detector_backend='skip',\n",
    "                                    model_name=face_img.EmbeddingModel.name, enforce_detection=False)\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "                session.commit()\n",
    "                updated_face_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "    if updated_face_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating embeddings for FaceImages in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_embeddings_qmagface(session, input_dir: str, force_update: bool = False, serfiq=None):\n",
    "\n",
    "    # General case\n",
    "    query = session.query(FaceImage,CroppedImage) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .filter(EmbeddingModel.name == 'QMagFace') \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector)\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    model = load_model()\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings QMagFace'):\n",
    "\n",
    "        img = face_img.CroppedImage.get_aligned_image(input_dir, ser_fiq = serfiq)\n",
    "        embedding = compute_qmagface_embeddings(img, model)\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            commit_updates(session, updated_face_images, FaceImage)\n",
    "\n",
    "    commit_updates(session, updated_face_images, FaceImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def update_embeddings_qmagface_old(session, input_dir:str, force_update: bool = False, serfiq = None):\n",
    "    \n",
    "    query = session.query(FaceImage,CroppedImage) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .filter(EmbeddingModel.name == 'QMagFace') \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector)\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    model = load_model()\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings QMagFace'):\n",
    "        \n",
    "        img = face_img.CroppedImage.get_aligned_image(input_dir, ser_fiq = serfiq)\n",
    "        \n",
    "        embedding = compute_qmagface_embeddings(img, model)\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "            \n",
    "\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "                session.commit()\n",
    "                updated_face_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "    if updated_face_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating embeddings for FaceImages in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def update_embeddings_arcface(session, input_dir:str, force_update: bool = False, serfiq = None):\n",
    "\n",
    "    # General case\n",
    "    query = session.query(FaceImage, Detector, Image) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector) \\\n",
    "        .join(Image, Image.image_id ==CroppedImage.image_id) \\\n",
    "        .filter(EmbeddingModel.name == 'ArcFace_normalized', Detector.name != 'mtcnn_serfiq')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings ArcFace general'):\n",
    "        embedding = DeepFace.represent(face_img.Image.get_image(input_dir), detector_backend=face_img.Detector.name,\n",
    "                                    model_name='ArcFace', enforce_detection=True, normalization = 'ArcFace')\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            commit_updates(session, updated_face_images, FaceImage)\n",
    "\n",
    "    commit_updates(session, updated_face_images, FaceImage)\n",
    "\n",
    "    # Mtcnn-serfiq\n",
    "    query = session.query(FaceImage, CroppedImage) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector)\\\n",
    "        .filter(EmbeddingModel.name == 'ArcFace_normalized', Detector.name == 'mtcnn_serfiq')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings ArcFace mtcnn-serfiq'):\n",
    "        embedding = DeepFace.represent(face_img.CroppedImage.get_aligned_image(input_dir, ser_fiq = serfiq), detector_backend='skip',\n",
    "                                    model_name='ArcFace', enforce_detection=False, normalization = 'ArcFace')\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            commit_updates(session, updated_face_images, FaceImage)\n",
    "\n",
    "    commit_updates(session, updated_face_images, FaceImage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def update_embeddings_arcface_old(session, input_dir:str, force_update: bool = False, serfiq = None):\n",
    "    \n",
    "    # General case\n",
    "    query = session.query(FaceImage, Detector, Image) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector) \\\n",
    "        .join(Image, Image.image_id ==CroppedImage.image_id) \\\n",
    "        .filter(EmbeddingModel.name == 'ArcFace_normalized', Detector.name != 'mtcnn_serfiq')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings DeepFace general'):\n",
    "        embedding = DeepFace.represent(face_img.Image.get_image(input_dir), detector_backend=face_img.Detector.name,\n",
    "                                    model_name='ArcFace', enforce_detection=True, normalization = 'ArcFace')\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "                session.commit()\n",
    "                updated_face_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "    if updated_face_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "\n",
    "    # Mtcnn-serfiq\n",
    "    query = session.query(FaceImage, CroppedImage) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector)\\\n",
    "        .filter(EmbeddingModel.name == 'ArcFace_normalized', Detector.name == 'mtcnn_serfiq', Detector.name != 'mediapipe')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings DeepFace mtcnn-serfiq'):\n",
    "        embedding = DeepFace.represent(face_img.CroppedImage.get_aligned_image(input_dir, ser_fiq = serfiq), detector_backend='skip',\n",
    "                                    model_name='ArcFace', enforce_detection=False, normalization = 'ArcFace')\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "                session.commit()\n",
    "                updated_face_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "    if updated_face_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating embeddings for FaceImages in the database\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update QualityImages\n",
    "Attributes associated to the QualityImage class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def update_quality_images(session, input_dir, serfiq=None, force_update: bool = False):\n",
    "    \n",
    "    update_ser_fiq(session, input_dir, serfiq = serfiq, force_update=force_update)\n",
    "    update_tface(session, input_dir,  serfiq = serfiq, force_update=force_update)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_ser_fiq(session, input_dir, serfiq=None, force_update: bool = False):\n",
    "\n",
    "    query = session.query(QualityImage, CroppedImage) \\\n",
    "        .join(QualityModel) \\\n",
    "        .join(FaceImage, FaceImage.faceImage_id == QualityImage.faceImage_id) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector) \\\n",
    "        .filter(EmbeddingModel.name == 'QMagFace',\n",
    "                QualityModel.name == 'ser_fiq'\n",
    "                )\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(QualityImage.quality == None)\n",
    "    all_rows = query.all()\n",
    "\n",
    "    updated_quality_images = []\n",
    "    count = 0\n",
    "\n",
    "    for row in tqdm(all_rows, desc='Computing SER-FIQ quality'):\n",
    "        aligned_img = row.CroppedImage.get_aligned_image(input_dir, ser_fiq=serfiq)\n",
    "\n",
    "        if aligned_img is None:\n",
    "            quality = None\n",
    "            row.QualityImage.quality = quality\n",
    "        else:\n",
    "            quality = serfiq.get_score(aligned_img, T=100)\n",
    "            row.QualityImage.quality = quality\n",
    "\n",
    "        updated_quality_images.append({\"qualityImage_id\": row.QualityImage.qualityImage_id, \"quality\": row.QualityImage.quality})\n",
    "        count += 1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            commit_updates(session, updated_quality_images, QualityImage)\n",
    "\n",
    "    commit_updates(session, updated_quality_images, QualityImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def update_ser_fiq_old(session, input_dir, serfiq=None, force_update: bool = False):\n",
    "    query = session.query(QualityImage, CroppedImage) \\\n",
    "        .join(QualityModel) \\\n",
    "        .join(FaceImage, FaceImage.faceImage_id == QualityImage.faceImage_id) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector) \\\n",
    "        .filter(EmbeddingModel.name == 'QMagFace',\n",
    "                QualityModel.name == 'ser_fiq'\n",
    "                )\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(QualityImage.quality == None)\n",
    "    all_rows = query.all()\n",
    "\n",
    "    updated_quality_images = []\n",
    "    count = 0\n",
    "\n",
    "    for row in tqdm(all_rows, desc='Computing SER-FIQ quality'):\n",
    "        aligned_img = row.CroppedImage.get_aligned_image(input_dir, ser_fiq=serfiq)\n",
    "\n",
    "        if aligned_img is None:\n",
    "            quality = None\n",
    "            row.QualityImage.quality = quality\n",
    "        else:\n",
    "            quality = serfiq.get_score(aligned_img, T=100)\n",
    "            row.QualityImage.quality = quality\n",
    "\n",
    "        updated_quality_images.append({\"qualityImage_id\": row.QualityImage.qualityImage_id, \"quality\": row.QualityImage.quality})\n",
    "        count += 1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(QualityImage, updated_quality_images)\n",
    "                session.commit()\n",
    "                updated_quality_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating SER-FIQ quality for QualityImages in the database\")\n",
    "\n",
    "    if updated_quality_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(QualityImage, updated_quality_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating SER-FIQ quality for QualityImages in the database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_tface(session, input_dir, serfiq, force_update: bool = False):\n",
    "    ser_fiq = serfiq\n",
    "\n",
    "    net, gpu_available = get_network()\n",
    "\n",
    "    # todo: Now it is only for QMagFace, it should be expanded to other embedding models. \n",
    "    # Is it ArcFace or another face recognition model?\n",
    "    \n",
    "    query = session.query(QualityImage, CroppedImage) \\\n",
    "        .join(QualityModel) \\\n",
    "        .join(FaceImage, FaceImage.faceImage_id == QualityImage.faceImage_id) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .filter(EmbeddingModel.name == 'QMagFace', \n",
    "                QualityModel.name == 'tface')\n",
    "        # .join(Image, Image.image_id == CroppedImage.image_id) \n",
    "        \n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(QualityImage.quality == None)\n",
    "    all_rows = (query.all())\n",
    "\n",
    "    updated_quality_images = []\n",
    "    count = 0\n",
    "\n",
    "    for row in tqdm(all_rows, desc='Computing TFace quality'):             \n",
    "\n",
    "        aligned_img = row.CroppedImage.get_aligned_image(input_dir, ser_fiq=serfiq) \n",
    "        quality = compute_tf_quality(aligned_img, net, gpu_available=gpu_available)             \n",
    "        \n",
    "        row.QualityImage.quality = quality\n",
    "        updated_quality_images.append({\"qualityImage_id\": row.QualityImage.qualityImage_id, \"quality\": row.QualityImage.quality})\n",
    "        count += 1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            commit_updates(session, updated_quality_images, QualityImage)\n",
    "\n",
    "    commit_updates(session, updated_quality_images, QualityImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def update_tface_old(session, input_dir, serfiq, force_update: bool = False):\n",
    "    ser_fiq = serfiq\n",
    "\n",
    "    net, gpu_available = get_network()\n",
    "\n",
    "    # todo: Now it is only for QMagFace, it should be expanded to other embedding models. \n",
    "    # Is it ArcFace or another face recognition model?\n",
    "    \n",
    "    query = session.query(QualityImage, CroppedImage) \\\n",
    "        .join(QualityModel) \\\n",
    "        .join(FaceImage, FaceImage.faceImage_id == QualityImage.faceImage_id) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .filter(EmbeddingModel.name == 'QMagFace', \n",
    "                QualityModel.name == 'tface')\n",
    "        # .join(Image, Image.image_id == CroppedImage.image_id) \n",
    "        \n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(QualityImage.quality == None)\n",
    "    all_rows = (query.all())\n",
    "\n",
    "    # for row in tqdm(all_rows[:5], desc='TRIM: Computing TFace quality'): \n",
    "    for row in tqdm(all_rows, desc='Computing TFace quality'):             \n",
    "\n",
    "        aligned_img = row.CroppedImage.get_aligned_image(input_dir, ser_fiq=serfiq) \n",
    "        quality = compute_tf_quality(aligned_img, net, gpu_available=gpu_available)             \n",
    "        \n",
    "        row.QualityImage.quality = quality\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql-face",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
