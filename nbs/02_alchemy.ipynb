{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Alchemy\n",
    "\n",
    "> Alchemy related functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains functions related to SQL Alchemy, which is a Python library used for working with databases. The main functions in this module are create_engine, Session, and Base. create_engine is used to create a connection to a database, Session is used to start a session with the database, and Base is used to define the structure of a database table. These functions are used to create, read, update, and delete (CRUD) data in a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp alchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 15:35:52.888920: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sql_face'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/jmacarulla/sql-face/nbs/02_alchemy.ipynb Cell 5\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/sql-face/nbs/02_alchemy.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdeepface\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommons\u001b[39;00m \u001b[39mimport\u001b[39;00m functions\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/sql-face/nbs/02_alchemy.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdeepface\u001b[39;00m \u001b[39mimport\u001b[39;00m DeepFace\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/sql-face/nbs/02_alchemy.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msql_face\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatabases\u001b[39;00m \u001b[39mimport\u001b[39;00m FaceDataBase\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/sql-face/nbs/02_alchemy.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msql_face\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtables\u001b[39;00m \u001b[39mimport\u001b[39;00m Base, Image, Detector, CroppedImage, EmbeddingModel, FaceImage, QualityModel, QualityImage \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/jmacarulla/sql-face/nbs/02_alchemy.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msql_face\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtables\u001b[39;00m \u001b[39mimport\u001b[39;00m Gender, Age, Race, Emotion\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sql_face'"
     ]
    }
   ],
   "source": [
    "#| exporti\n",
    "import os\n",
    "\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sqlalchemy import create_engine, or_\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from deepface.commons import functions\n",
    "from deepface import DeepFace\n",
    "\n",
    "from sql_face.databases import FaceDataBase\n",
    "from sql_face.tables import Base, Image, Detector, CroppedImage, EmbeddingModel, FaceImage, QualityModel, QualityImage \n",
    "from sql_face.tables import Gender, Age, Race, Emotion\n",
    "from sql_face.tface import get_network, compute_tf_quality\n",
    "from sql_face.qmagface import load_model, compute_qmagface_embeddings\n",
    "from sql_face.faceangles import compute_pose, compute_angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect session\n",
    "Connect to SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_session(\n",
    "    output_dir:str, # Output directory\n",
    "    db_name:str, # .db file name\n",
    "                    ): # SQL alchemy session \n",
    "    db_path = os.path.join(output_dir,db_name+'.db')       \n",
    "    engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "    if not os.path.exists(db_path):\n",
    "        if not os.path.exists(output_dir):\n",
    "            print(f'Creating output directory at {output_dir}')\n",
    "            os.mkdir(output_dir)\n",
    "            \n",
    "        print(f'Creating Db file at {db_path}')        \n",
    "    \n",
    "    # If the database file exists, update the tables in Base\n",
    "    Base.metadata.create_all(engine, checkfirst=True)\n",
    "    Session = sessionmaker()\n",
    "    Session.configure(bind=engine)\n",
    "    session = Session()\n",
    "    return session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table creators \n",
    "The functions in this section are used to create tables in the database for storing information about face detectors, images, cropped images, and other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_detectors(session, #SQL alchemy session object\n",
    "                    detector_names: List[str] # List of detectors to add to the database.\n",
    "                    ):\n",
    "    existing_detectors = {d.name for d in session.query(Detector).all()}\n",
    "    new_detectors = [Detector(name=name) for name in detector_names if name not in existing_detectors]\n",
    "    session.bulk_save_objects(new_detectors)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def create_detectors_old(\n",
    "                session, #SQL alchemy session object\n",
    "                detector_names: List[str] # List of detectors to add to the database.\n",
    "                ):\n",
    "        \n",
    "        for detector_entry in detector_names:\n",
    "                detector = (\n",
    "                        session.query(Detector)\n",
    "                        .filter(Detector.name == detector_entry)\n",
    "                        .one_or_none()\n",
    "                        )\n",
    "                if detector is None:\n",
    "                        detector = Detector(name=detector_entry)\n",
    "                        session.add(detector)\n",
    "                session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_embedding_models(session, #SQL alchemy session object\n",
    "                            embedding_model_names: List[str]): # List of detectors to add to the database.\n",
    "    existing_models = {em.name for em in session.query(EmbeddingModel).all()}\n",
    "    new_models = [EmbeddingModel(name=name) for name in embedding_model_names if name not in existing_models]\n",
    "    session.bulk_save_objects(new_models)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def create_embedding_models_old(session, #SQL alchemy session object\n",
    "                            embedding_model_names: List[str]): # List of embedding model names to add to the database.\n",
    "        \n",
    "        for emb_model_entry in embedding_model_names:\n",
    "            emb_model = (\n",
    "                session.query(EmbeddingModel)\n",
    "                    .filter(EmbeddingModel.name == emb_model_entry)\n",
    "                    .one_or_none()\n",
    "            )\n",
    "            if emb_model is None:\n",
    "                emb_model = EmbeddingModel(name=emb_model_entry)\n",
    "                session.add(emb_model)\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def create_quality_models(session, #SQL alchemy session object\n",
    "                        quality_model_names: List[str]): # List of quality models to add to the database.\n",
    "    existing_models = {qm.name for qm in session.query(QualityModel).all()}\n",
    "    new_models = [QualityModel(name=name) for name in quality_model_names if name not in existing_models]\n",
    "    session.bulk_save_objects(new_models)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def create_quality_models_old(session, # SQL alchemy session object.\n",
    "                            quality_model_names: List[str]): # List of quality models to add to the database.\n",
    "        \n",
    "        for qua_model_entry in quality_model_names:\n",
    "            qua_model = (\n",
    "                session.query(QualityModel)\n",
    "                    .filter(QualityModel.name == qua_model_entry)\n",
    "                    .one_or_none()\n",
    "            )\n",
    "            if qua_model is None:\n",
    "                qua_model = QualityModel(name=qua_model_entry)\n",
    "                session.add(qua_model)\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def fill_cropped_image_serfiq(cr_img: CroppedImage, # CroppedImage object to be filled with bounding box and landmarks information.\n",
    "                                input_dir, # Directory where the images are stored.\n",
    "                                ser_fiq): #SERFIQ model object.\n",
    "                                \n",
    "        image = cr_img.images.get_image(input_dir)\n",
    "        aligned_img = ser_fiq.apply_mtcnn(image)\n",
    "        if aligned_img is None:\n",
    "            cr_img.bounding_box = []\n",
    "            cr_img.landmarks = []\n",
    "            cr_img.face_detected = False\n",
    "        elif len(aligned_img) == 0:\n",
    "            cr_img.bounding_box = []\n",
    "            cr_img.landmarks = []\n",
    "            cr_img.face_detected = False\n",
    "        else:\n",
    "            bbox, points = ser_fiq.detector.detect_face(image)\n",
    "            cr_img.bounding_box = bbox[0].tolist()\n",
    "            cr_img.landmarks = points[0].tolist()\n",
    "            cr_img.face_detected = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def fill_cropped_image_general(cr_img: CroppedImage, input_dir, **kwargs):\n",
    "    image = cr_img.images.get_image(input_dir)      \n",
    "    \n",
    "    try:\n",
    "        img_cropped, bounding_box = functions.preprocess_face(img=image,\n",
    "                                                                detector_backend=cr_img.detectors.name,\n",
    "                                                                enforce_detection=True,\n",
    "                                                                return_region=True)\n",
    "        \n",
    "        cr_img.bounding_box = bounding_box\n",
    "        cr_img.face_detected = True\n",
    "\n",
    "    except ValueError:\n",
    "        cr_img.bounding_box = []\n",
    "        cr_img.face_detected = False\n",
    "        #todo: change warning if the image is a video(frame).\n",
    "        print(f'Face not found in {cr_img.images.path} with {cr_img.detectors.name}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_cropped_images(session, input_dir:str, serfiq = None):\n",
    "        \n",
    "        all_detectors = (session.query(Detector).all())\n",
    "        for det in all_detectors:\n",
    "\n",
    "            # Load SERFIQ model if neccesary\n",
    "            if det.name == 'mtcnn_serfiq':\n",
    "                \n",
    "                fill_cropped_image = fill_cropped_image_serfiq\n",
    "            else:\n",
    "                \n",
    "                fill_cropped_image = fill_cropped_image_general\n",
    "\n",
    "            subquery = session.query(CroppedImage.image_id) \\\n",
    "                .filter(CroppedImage.detectors == det)\n",
    "            images = (\n",
    "                session.query(Image)\n",
    "                    .filter(Image.image_id.notin_(subquery))\n",
    "                    .all()\n",
    "            )\n",
    "\n",
    "            cropped_images = []\n",
    "            count = 0\n",
    "            for img in tqdm(images, desc=f'Creating CroppedImages for detector {det.name}'):\n",
    "               \n",
    "                cropped_image = CroppedImage()\n",
    "                cropped_image.image_id = img.image_id\n",
    "                cropped_image.detector_id = det.detector_id\n",
    "                cropped_image.images = img\n",
    "                cropped_image.detectors = det\n",
    "                fill_cropped_image(cropped_image, input_dir, ser_fiq = serfiq)\n",
    "                cropped_images.append(cropped_image)\n",
    "                count += 1\n",
    "\n",
    "\n",
    "                if count % 100 == 0:\n",
    "                    session.bulk_save_objects(cropped_images)\n",
    "                    try:\n",
    "                        session.commit()\n",
    "                    except IntegrityError:\n",
    "                        session.rollback()\n",
    "                        raise IntegrityError(\"Could not commit CroppedImages\")\n",
    "                    cropped_images = []\n",
    "                    \n",
    "\n",
    "            if cropped_images:          \n",
    "                session.bulk_save_objects(cropped_images)\n",
    "                try:\n",
    "                    session.commit()\n",
    "                except IntegrityError:\n",
    "                    session.rollback()\n",
    "                    raise IntegrityError(\"Could not commit CroppedImages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def create_cropped_images_old(session, input_dir:str, serfiq = None):\n",
    "        \n",
    "        all_detectors = (session.query(Detector).all())\n",
    "        for det in all_detectors:\n",
    "\n",
    "            # Load SERFIQ model if neccesary\n",
    "            if det.name == 'mtcnn_serfiq':\n",
    "                \n",
    "                fill_cropped_image = fill_cropped_image_serfiq\n",
    "            else:\n",
    "                \n",
    "                fill_cropped_image = fill_cropped_image_general\n",
    "\n",
    "            subquery = session.query(CroppedImage.image_id) \\\n",
    "                .filter(CroppedImage.detectors == det)\n",
    "            images = (\n",
    "                session.query(Image)\n",
    "                    .filter(Image.image_id.notin_(subquery))\n",
    "                    .all()\n",
    "            )\n",
    "\n",
    "            # for img in tqdm(images[:5], desc=f'TRIM Creating Cropped Images for detector {det.name}'):\n",
    "            for img in tqdm(images, desc=f'Creating Cropped Images for detector {det.name}'):\n",
    "                cropped_image = CroppedImage()\n",
    "                cropped_image.images = img\n",
    "                cropped_image.detectors = det\n",
    "                fill_cropped_image(cropped_image, input_dir, ser_fiq = serfiq)\n",
    "                session.add(cropped_image)\n",
    "                session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_face_images(session):\n",
    "    all_embedding_models = (session.query(EmbeddingModel).all())\n",
    "    for emb in tqdm(all_embedding_models, desc='Embedding models'):\n",
    "        subquery = session.query(FaceImage.croppedImage_id) \\\n",
    "            .filter(FaceImage.embeddingModels == emb)\n",
    "        cropped_images = (\n",
    "            session.query(CroppedImage) \\\n",
    "                .filter(CroppedImage.croppedImage_id.notin_(subquery),\n",
    "                        CroppedImage.face_detected == True)\n",
    "                .all()\n",
    "        )\n",
    "        count = 0\n",
    "        face_images_to_add = []\n",
    "        for cr_img in tqdm(cropped_images, desc=f'Face images in {emb.name}'):\n",
    "            face_image = FaceImage(croppedImage_id=cr_img.croppedImage_id, embeddingModel_id=emb.embeddingModel_id)\n",
    "            face_images_to_add.append(face_image)\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                session.bulk_save_objects(face_images_to_add)\n",
    "                session.commit()\n",
    "                face_images_to_add = []\n",
    "\n",
    "            if count % 100 == 0:\n",
    "                session.bulk_save_objects(face_images_to_add)\n",
    "                try:\n",
    "                    session.commit()\n",
    "                except IntegrityError:\n",
    "                    session.rollback()\n",
    "                    raise IntegrityError(\"Could not commit face images\")\n",
    "                face_images_to_add = []\n",
    "\n",
    "        if face_images_to_add:\n",
    "            session.bulk_save_objects(face_images_to_add)\n",
    "            try:\n",
    "                session.commit()\n",
    "            except IntegrityError:\n",
    "                session.rollback()\n",
    "                raise IntegrityError(\"Could not commit face images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def create_face_images_old(session):\n",
    "        \n",
    "    all_embedding_models = (session.query(EmbeddingModel).all())\n",
    "    for emb in tqdm(all_embedding_models, desc='Embedding models'):\n",
    "        subquery = session.query(FaceImage.croppedImage_id) \\\n",
    "            .filter(FaceImage.embeddingModels == emb)\n",
    "        cropped_images = (\n",
    "            session.query(CroppedImage) \\\n",
    "                .filter(CroppedImage.croppedImage_id.notin_(subquery),\n",
    "                        CroppedImage.face_detected == True)\n",
    "                .all()\n",
    "        )\n",
    "\n",
    "        for cr_img in tqdm(cropped_images, desc=f'Face images in {emb.name}'):\n",
    "            face_image = FaceImage()\n",
    "            face_image.croppedImages = cr_img\n",
    "            face_image.embeddingModels = emb\n",
    "            session.add(face_image)\n",
    "            session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_quality_images_new(session):\n",
    "    all_quality_models = session.query(QualityModel).filter(QualityModel.name == \"ser_fiq\").all()\n",
    "\n",
    "    for qua in tqdm(all_quality_models, desc='Quality models'):\n",
    "        subquery = session.query(QualityImage.faceImage_id) \\\n",
    "            .filter(QualityImage.qualityModels == qua)\n",
    "        face_images = (\n",
    "            session.query(FaceImage)\n",
    "            .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id)\n",
    "            .join(Detector)\n",
    "            .join(EmbeddingModel)\n",
    "            .filter(FaceImage.faceImage_id.notin_(subquery),\n",
    "                    Detector.name == 'mtcnn_serfiq',\n",
    "                    EmbeddingModel.name == 'QMagFace')\n",
    "            .all()\n",
    "        )\n",
    "\n",
    "        count = 0\n",
    "        qua_images = []\n",
    "\n",
    "        for face_img in tqdm(face_images, desc=f'Quality images in {qua.name}'):\n",
    "            qua_image = QualityImage()\n",
    "            qua_image.faceImages = face_img\n",
    "            qua_image.qualityModels = qua\n",
    "            qua_image.faceImage_id = face_img.faceImage_id\n",
    "            qua_image.qualityModel_id = qua.qualityModel_id\n",
    "            qua_images.append(qua_image)\n",
    "            count += 1\n",
    "\n",
    "            if count % 100 == 0:\n",
    "                session.bulk_save_objects(qua_images)\n",
    "                try:\n",
    "                    session.commit()\n",
    "                except IntegrityError:\n",
    "                    session.rollback()\n",
    "                    raise IntegrityError(\"Could not commit quality images\")\n",
    "                qua_images = []\n",
    "\n",
    "    if qua_images:\n",
    "        session.bulk_save_objects(qua_images)\n",
    "        try:\n",
    "            session.commit()\n",
    "        except IntegrityError:\n",
    "            session.rollback()\n",
    "            raise IntegrityError(\"Could not commit quality images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def create_quality_images(session):\n",
    "    #TODO: change to \n",
    "    all_quality_models = (session.query(QualityModel).filter(QualityModel.name == \"ser_fiq\").all())\n",
    "    \n",
    "    for qua in tqdm(all_quality_models, desc='Quality models'):\n",
    "        subquery = session.query(QualityImage.faceImage_id) \\\n",
    "            .filter(QualityImage.qualityModels == qua)\n",
    "        face_images = (\n",
    "            session.query(FaceImage) \\\n",
    "                .filter(FaceImage.faceImage_id.notin_(subquery))\n",
    "                .all()\n",
    "        )\n",
    "\n",
    "        count = 0\n",
    "        qua_images = []\n",
    "\n",
    "        for face_img in tqdm(face_images, desc=f'Quality images in {qua.name}'):\n",
    "            qua_image = QualityImage()\n",
    "            qua_image.faceImages = face_img\n",
    "            qua_image.qualityModels = qua\n",
    "            qua_image.faceImage_id = face_img.faceImage_id\n",
    "            qua_image.qualityModel_id = qua.qualityModel_id\n",
    "            qua_images.append(qua_image)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "            if count % 100 == 0:\n",
    "                session.bulk_save_objects(qua_images)\n",
    "                try:\n",
    "                    session.commit()\n",
    "                except IntegrityError:\n",
    "                    session.rollback()\n",
    "                    raise IntegrityError(\"Could not commit quality images\")\n",
    "                qua_images = []\n",
    "\n",
    "\n",
    "    if qua_images:\n",
    "        session.bulk_save_objects(qua_images)\n",
    "        try:\n",
    "            session.commit()\n",
    "        except IntegrityError:\n",
    "            session.rollback()\n",
    "            raise IntegrityError(\"Could not commit quality images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def create_quality_images_old(session):\n",
    "        \n",
    "        all_quality_models = (session.query(QualityModel).all())\n",
    "        for qua in tqdm(all_quality_models, desc='Quality models'):\n",
    "            subquery = session.query(QualityImage.faceImage_id) \\\n",
    "                .filter(QualityImage.qualityModels == qua)\n",
    "            face_images = (\n",
    "                session.query(FaceImage) \\\n",
    "                    .filter(FaceImage.faceImage_id.notin_(subquery))\n",
    "                    .all()\n",
    "            )\n",
    "\n",
    "            for face_img in tqdm(face_images, desc=f'Quality images in {qua.name}'):\n",
    "                qua_image = QualityImage()\n",
    "                qua_image.faceImages = face_img\n",
    "                qua_image.qualityModels = qua\n",
    "                session.add(qua_image)\n",
    "                session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table attribute update\n",
    "Once the tables are created, functions to fill in the Image, CroppedImage, FaceImage and Qualityimage attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_gender(session, input_dir:str, databases:List[FaceDataBase], force_update: bool = False):\n",
    "\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.gender == None)\n",
    "        all_img = (query.all())\n",
    "\n",
    "        updated_images = []\n",
    "        count = 0\n",
    "\n",
    "        # for img in tqdm(all_img[:10], desc='TRIM Update gender'):\n",
    "        for img in tqdm(all_img, desc='Update gender'):\n",
    "\n",
    "            try:\n",
    "                filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=['gender'], enforce_detection=True, detector_backend = 'mediapipe') # detector_backend = 'mediapipe'\n",
    "                img.gender = Gender(filters[\"gender\"])\n",
    "                \n",
    "            except ValueError:\n",
    "                img.gender = None\n",
    "\n",
    "            updated_images.append({\"image_id\": img.image_id, \"gender\": img.gender})\n",
    "            \n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                session.bulk_update_mappings(Image, updated_images)\n",
    "                session.commit()\n",
    "                updated_images = []\n",
    "        if updated_images:\n",
    "            session.bulk_update_mappings(Image, updated_images)\n",
    "            session.flush()\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "def update_gender_old(session, input_dir:str, databases:List[FaceDataBase], force_update: bool = False):\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.gender == None)\n",
    "        all_img = (query.all())\n",
    "\n",
    "        # for img in tqdm(all_img[:10], desc='TRIM Update gender'):\n",
    "        for img in tqdm(all_img, desc='Update gender'):\n",
    "            filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=[\n",
    "                                       'gender'], enforce_detection=False)\n",
    "            img.gender = Gender(filters[\"gender\"])\n",
    "            session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_age(session, input_dir:str, databases:List[FaceDataBase],force_update: bool = False):\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.age == None)\n",
    "        all_img = (query.all())\n",
    "\n",
    "        updated_images = []\n",
    "        count = 0\n",
    "\n",
    "        for img in tqdm(all_img, desc='Update age'):\n",
    "            try:\n",
    "                filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=['age'], enforce_detection=True, detector_backend = 'mediapipe')\n",
    "                age = filters[\"age\"]\n",
    "                img.age_number = age\n",
    "                img.age = Age.age2enum(age)\n",
    "\n",
    "                \n",
    "            except ValueError:\n",
    "                img.age = None\n",
    "                img.age_number = None\n",
    "                \n",
    "                \n",
    "\n",
    "            updated_images.append({\"image_id\": img.image_id, \"age_number\": img.age_number, \"age\": img.age})\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "            if count % 100 == 0:\n",
    "                session.bulk_update_mappings(Image, updated_images)\n",
    "                session.flush()\n",
    "                session.commit()\n",
    "                updated_images = []\n",
    "\n",
    "        if updated_images:\n",
    "            session.bulk_update_mappings(Image, updated_images)\n",
    "            session.flush()\n",
    "        session.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "def update_age_old(session, input_dir:str, databases:List[FaceDataBase],force_update: bool = False):\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.age == None)\n",
    "        all_img = (query.all())\n",
    "        for img in tqdm(all_img, desc='Update age'):\n",
    "            filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=[\n",
    "                                       'age'], enforce_detection=False)\n",
    "            age = filters[\"age\"]\n",
    "            img.age_number = age\n",
    "            img.age = Age.age2enum(age)\n",
    "            \n",
    "            \n",
    "            session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_emotion(session, input_dir:str, databases:List[FaceDataBase],force_update: bool = False):\n",
    "\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.emotion == None)\n",
    "        all_img = (query.all())\n",
    "\n",
    "        updated_images = []\n",
    "        count = 0\n",
    "\n",
    "        for img in tqdm(all_img, desc='Update facial expression (emotion)'):\n",
    "\n",
    "            try:\n",
    "                filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=['emotion'], enforce_detection=True, detector_backend = 'mediapipe')\n",
    "                emotions = filters[\"emotion\"]\n",
    "                prime_emotion = max(emotions, key=emotions.get)\n",
    "                img.emotion = Emotion(prime_emotion)\n",
    "            except ValueError:\n",
    "                img.emotion = None\n",
    "\n",
    "            updated_images.append({\"image_id\": img.image_id, \"emotion\": img.emotion})\n",
    "            \n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                session.bulk_update_mappings(Image, updated_images)\n",
    "                session.flush()\n",
    "                session.commit()\n",
    "                updated_images = []\n",
    "        if updated_images:\n",
    "            session.bulk_update_mappings(Image, updated_images)\n",
    "            session.flush()\n",
    "        session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def update_emotion_old(session, input_dir:str, databases:List[FaceDataBase],force_update: bool = False):\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.emotion == None)\n",
    "        all_img = (query.all())\n",
    "        for img in tqdm(all_img, desc='Update facial expression (emotion)'):\n",
    "            filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=[\n",
    "                                       'emotion'], enforce_detection=False)\n",
    "\n",
    "            emotions = filters[\"emotion\"]\n",
    "            prime_emotion = max(emotions, key=emotions.get)\n",
    "            img.emotion = Emotion(prime_emotion)\n",
    "            session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_race(session, input_dir:str, databases:List[FaceDataBase], force_update: bool = False):\n",
    "    \n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.race == None)\n",
    "        all_img = (query.all())\n",
    "\n",
    "        updated_images = []\n",
    "        count = 0\n",
    "\n",
    "        for img in tqdm(all_img, desc='Update race'):\n",
    "            try:\n",
    "                filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=['race'], enforce_detection=True, detector_backend = 'mtcnn')\n",
    "                races = filters[\"race\"]\n",
    "                prime_race = max(races, key=races.get)\n",
    "                img.race = Race(prime_race)\n",
    "            except ValueError:\n",
    "                img.race = None\n",
    "\n",
    "            updated_images.append({\"image_id\": img.image_id, \"race\": img.race})\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                session.bulk_update_mappings(Image, updated_images)\n",
    "                session.flush()\n",
    "                session.commit()\n",
    "                updated_images = []\n",
    "        if updated_images:\n",
    "            session.bulk_update_mappings(Image, updated_images)\n",
    "            session.flush()\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "\n",
    "def update_race_old(session, input_dir:str, databases:List[FaceDataBase], force_update: bool = False):\n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "        if not force_update:\n",
    "            query = query.filter(Image.race == None)\n",
    "        all_img = (query.all())\n",
    "        for img in tqdm(all_img, desc='Update race'):\n",
    "            filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=[\n",
    "                                    'race'], enforce_detection=False)\n",
    "\n",
    "            races = filters[\"race\"]\n",
    "            prime_race = max(races, key=races.get)\n",
    "            img.race = Race(prime_race)\n",
    "            session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_angles(session, input_dir: str, databases: List[FaceDataBase], force_update: bool = False):\n",
    "    \n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "\n",
    "        if not force_update:\n",
    "            query = query.filter(or_(Image.angle_roll == None, Image.angle_yaw == None, Image.angle_pitch == None))\n",
    "\n",
    "        all_images = query.all()\n",
    "\n",
    "        ncount = 100\n",
    "        updated_images = []\n",
    "        count = ncount\n",
    "\n",
    "        for img in tqdm(all_images, desc='Update angles'):\n",
    "        \n",
    "            img_array = img.get_image(input_dir)\n",
    "            a_pitch, a_yaw, a_roll = compute_angles(img_array)\n",
    "\n",
    "            upd_img = {}\n",
    "            if a_roll:\n",
    "                upd_img['angle_roll'] = a_roll\n",
    "                    \n",
    "            if a_yaw:\n",
    "                upd_img['angle_yaw'] = a_yaw\n",
    "                        \n",
    "            if a_pitch:\n",
    "                upd_img['angle_pitch'] = a_pitch\n",
    "            \n",
    "            if upd_img:\n",
    "                upd_img ['image_id'] =img.image_id\n",
    "                updated_images.append(upd_img)\n",
    " \n",
    "                count -= 1\n",
    "\n",
    "                if count == 0:\n",
    "                    session.bulk_update_mappings(Image, updated_images)\n",
    "                    session.flush() \n",
    "                    session.commit()\n",
    "                    updated_images = []\n",
    "                    count = ncount\n",
    "\n",
    "        if updated_images:\n",
    "            session.bulk_update_mappings(Image, updated_images)\n",
    "            session.flush()\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_pose(session, input_dir: str, databases: List[FaceDataBase], force_update: bool = False):\n",
    "    \n",
    "    for db in databases:\n",
    "        query = session.query(Image).filter(Image.source == db.source)\n",
    "\n",
    "        if not force_update:\n",
    "            query = query.filter(or_(Image.roll == None, Image.yaw == None, Image.pitch == None))\n",
    "\n",
    "        all_images = query.all()\n",
    "\n",
    "        ncount = 100\n",
    "        updated_images = []\n",
    "        count = ncount\n",
    "\n",
    "        for img in tqdm(all_images, desc='Update pose'):\n",
    "        \n",
    "            angles = (img.angle_pitch, img.angle_yaw, img.angle_roll)\n",
    "            pitch, yaw, roll = compute_pose(angles)\n",
    "\n",
    "            upd_img = {}\n",
    "            if roll:\n",
    "                if force_update or not img.roll:\n",
    "                    upd_img[\"roll\"] = roll        \n",
    "            if yaw:\n",
    "                if force_update or not img.yaw:\n",
    "                    upd_img[\"yaw\"] = yaw\n",
    "            \n",
    "            if pitch:\n",
    "                if force_update or not img.pitch:\n",
    "                    upd_img[\"pitch\"] = pitch\n",
    "\n",
    "            if upd_img:\n",
    "                upd_img ['image_id'] =img.image_id\n",
    "                updated_images.append(upd_img)      \n",
    "\n",
    "\n",
    "                count -= 1\n",
    "\n",
    "                if count == 0:\n",
    "                    session.bulk_update_mappings(Image, updated_images)\n",
    "                    session.flush() \n",
    "                    session.commit()\n",
    "                    updated_images = []\n",
    "                    count = ncount\n",
    "\n",
    "        if updated_images:\n",
    "            session.bulk_update_mappings(Image, updated_images)\n",
    "            session.flush()\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_images(session, input_dir,\n",
    "                databases:List[FaceDataBase], \n",
    "                attributes: List[str], \n",
    "                force_update: bool = False\n",
    "                ):\n",
    "\n",
    "    update_functions = {\n",
    "        'gender': update_gender,\n",
    "        'age': update_age,\n",
    "        'emotion': update_emotion,\n",
    "        'race': update_race,\n",
    "        'angles': update_angles,\n",
    "        'pose': update_pose\n",
    "    }\n",
    "\n",
    "    for attribute in attributes:\n",
    "        if attribute in update_functions:\n",
    "            update_functions[attribute](session, input_dir, databases, force_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "\n",
    "def update_images_old(session, input_dir,\n",
    "                databases:List[FaceDataBase], \n",
    "                attributes: List[str], \n",
    "                force_update: bool = False\n",
    "                ):\n",
    "\n",
    "    \"Updates Image attributes\"\n",
    "    if 'gender' in attributes:\n",
    "        update_gender(session, input_dir, databases, force_update)\n",
    "\n",
    "    if 'age' in attributes:\n",
    "        update_age(session, input_dir, databases, force_update)\n",
    "\n",
    "    if 'emotion' in attributes:\n",
    "        update_emotion(session, input_dir, databases, force_update)\n",
    "    \n",
    "    if 'race' in attributes:\n",
    "        update_race(session, input_dir, databases, force_update) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# TODO: refactoring so Deepface attributes are all together in a single function.\n",
    "\n",
    "def update_images_attributes_together(session, input_dir, databases:List[FaceDataBase], attributes: List[str], force_update: bool = False):\n",
    "    \n",
    "    query = session.query(Image).join(FaceDataBase).filter(FaceDataBase.source.in_([db.source for db in databases]))\n",
    "    if not force_update:\n",
    "        query = query.filter(or_(*[Image.__dict__[attribute] == None for attribute in attributes]))\n",
    "    all_imgs = (query.all())\n",
    "    updated_images = []\n",
    "    count = 0\n",
    "    for img in tqdm(all_imgs, desc='Updating images attributes'):\n",
    "        filters = DeepFace.analyze(img_path=img.get_image(input_dir), actions=attributes, enforce_detection=True)\n",
    "        for attribute in attributes:\n",
    "            if attribute in filters:\n",
    "                if attribute == 'gender':\n",
    "                    img.gender = Gender(filters[\"gender\"])\n",
    "                elif attribute == 'age':\n",
    "                    img.age_number = filters[\"age\"]\n",
    "                    img.age = Age.age2enum(filters[\"age\"])\n",
    "                elif attribute == 'emotion':\n",
    "                    prime_emotion = max(filters[\"emotion\"], key=filters[\"emotion\"].get)\n",
    "                    img.emotion = Emotion(prime_emotion)\n",
    "                elif attribute == 'race':\n",
    "                    prime_race = max(filters[\"race\"], key=filters[\"race\"].get)\n",
    "                    img.race = Race(prime_race)\n",
    "        updated_images.append({\"image_id\": img.image_id, **{attribute: getattr(img, attribute) for attribute in attributes}})\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            session.bulk_update_mappings(Image, updated_images)\n",
    "            session.commit()\n",
    "            updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def update_cropped_images(session, input_dir:str, force_update: bool = False, serfiq = None):\n",
    "        \n",
    "    query = session.query(CroppedImage).join(Detector)\n",
    "    \n",
    "    if not force_update:\n",
    "        query = query.filter(or_(CroppedImage.face_detected == None, CroppedImage.bounding_box == None))\n",
    "\n",
    "    query_serfiq = query.filter(Detector.name == 'mtcnn_serfiq')\n",
    "    query_general = query.filter(Detector.name != 'mtcnn_serfiq')\n",
    "\n",
    "    all_cr_img_serfiq = (query_serfiq.all())\n",
    "    all_cr_img_general = (query_general.all())\n",
    "\n",
    "    updated_images = []\n",
    "    count = 0\n",
    "    \n",
    "    if all_cr_img_serfiq:\n",
    "        # ser_fiq = serfiq\n",
    "        fill_cropped_image = fill_cropped_image_serfiq\n",
    "        for cr_img in tqdm(all_cr_img_serfiq, desc='Update cropped images serfiq'):\n",
    "            fill_cropped_image(cr_img, input_dir, ser_fiq = serfiq)\n",
    "            updated_images.append(cr_img)\n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                session.bulk_update_mappings(CroppedImage, updated_images)\n",
    "                session.flush()\n",
    "                updated_images = []\n",
    "\n",
    "    # ser_fiq = None\n",
    "    fill_cropped_image = fill_cropped_image_general\n",
    "\n",
    "    for cr_img in tqdm(all_cr_img_general, desc='Update cropped images'):\n",
    "        fill_cropped_image(cr_img, input_dir, ser_fiq = serfiq)\n",
    "        session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_face_images(session, input_dir:str, force_update: bool = False, serfiq = None):\n",
    "    # update_embeddings_deepface(session, input_dir, force_update, serfiq = serfiq)\n",
    "    update_embeddings_qmagface(session, input_dir, force_update, serfiq = serfiq)\n",
    "    # update_embeddings_arcface(session, input_dir, force_update, serfiq = serfiq)\n",
    "# self.update_confusion_score(force_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_embeddings_deepface(session, input_dir:str, force_update: bool = False, serfiq = None):\n",
    "\n",
    "    # General case\n",
    "    query = session.query(FaceImage, EmbeddingModel, Detector, Image) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector) \\\n",
    "        .join(Image, Image.image_id ==CroppedImage.image_id) \\\n",
    "        .filter(EmbeddingModel.name.notin_(['FaceVACs','QMagFace','ArcFace_normalized']), Detector.name != 'mtcnn_serfiq', Detector.name != 'mediapipe')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings DeepFace general'):\n",
    "        embedding = DeepFace.represent(face_img.Image.get_image(input_dir), detector_backend=face_img.Detector.name,\n",
    "                                    model_name=face_img.EmbeddingModel.name, enforce_detection=True)\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "                session.commit()\n",
    "                updated_face_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "    if updated_face_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "\n",
    "    # Mtcnn-serfiq\n",
    "    query = session.query(FaceImage, EmbeddingModel, CroppedImage) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector)\\\n",
    "        .filter(EmbeddingModel.name.notin_(['FaceVACs','QMagFace','ArcFace_normalized', 'SFace']), Detector.name == 'mtcnn_serfiq', Detector.name != 'mediapipe')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings DeepFace mtcnn-serfiq'):\n",
    "        embedding = DeepFace.represent(face_img.CroppedImage.get_aligned_image(input_dir, ser_fiq = serfiq), detector_backend='skip',\n",
    "                                    model_name=face_img.EmbeddingModel.name, enforce_detection=False)\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "                session.commit()\n",
    "                updated_face_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "    if updated_face_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating embeddings for FaceImages in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def update_embeddings_deepface_old(session, input_dir:str, force_update: bool = False):\n",
    "    \n",
    "    query = session.query(FaceImage, EmbeddingModel, Detector, Image) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector) \\\n",
    "        .join(Image, Image.image_id == CroppedImage.image_id) \\\n",
    "        .filter(EmbeddingModel.name != 'FaceVACs', EmbeddingModel.name != 'QMagFace', Detector.name != 'mtcnn_serfiq')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings DeepFace'):\n",
    "        embedding = DeepFace.represent(face_img.Image.get_image(input_dir), detector_backend=face_img.Detector.name,\n",
    "                                        model_name=face_img.EmbeddingModel.name, enforce_detection=True)\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_embeddings_qmagface(session, input_dir:str, force_update: bool = False, serfiq = None):\n",
    "    #todo: removed mediapipe to save time. Put it back.\n",
    "    query = session.query(FaceImage,CroppedImage) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .filter(EmbeddingModel.name == 'QMagFace') \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector)\\\n",
    "        .filter(Detector.name == 'mtcnn_serfiq')\n",
    "        # .filter(Detector.name != 'mediapipe')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    model = load_model()\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings QMagFace'):\n",
    "        \n",
    "        try:\n",
    "            img = face_img.CroppedImage.get_aligned_image(input_dir, ser_fiq = serfiq)\n",
    "            embedding = compute_qmagface_embeddings(img, model)\n",
    "            face_img.FaceImage.embeddings = embedding\n",
    "        except:\n",
    "            img = face_img.CroppedImage.get_aligned_image(input_dir, ser_fiq = serfiq)\n",
    "            embedding = None\n",
    "            face_img.FaceImage.embeddings = embedding\n",
    "            print(f'Problem with embedding in Image id {face_img.CroppedImage.image_id}')\n",
    "\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "                session.commit()\n",
    "                updated_face_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "    if updated_face_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating embeddings for FaceImages in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def update_embeddings_qmagface_old(session, input_dir:str, force_update: bool = False):\n",
    "    \n",
    "    query = session.query(FaceImage, CroppedImage) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector) \\\n",
    "        .join(Image, Image.image_id == CroppedImage.image_id) \\\n",
    "        .filter(EmbeddingModel.name == 'QMagFace')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    model = load_model()\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings QMagFace'):\n",
    "        img = face_img.CroppedImage.get_aligned_image(input_dir)\n",
    "        embedding = compute_qmagface_embeddings(img, model)\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_embeddings_arcface(session, input_dir:str, force_update: bool = False, serfiq = None):\n",
    "    #todo: removed mediapipe, add later.\n",
    "    # General case\n",
    "    query = session.query(FaceImage, Detector, Image) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage,CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector) \\\n",
    "        .join(Image, Image.image_id ==CroppedImage.image_id) \\\n",
    "        .filter(EmbeddingModel.name == 'ArcFace_normalized', Detector.name != 'mtcnn_serfiq', Detector.name != 'mediapipe')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings DeepFace general'):\n",
    "        embedding = DeepFace.represent(face_img.Image.get_image(input_dir), detector_backend=face_img.Detector.name,\n",
    "                                    model_name='ArcFace', enforce_detection=True, normalization = 'ArcFace')\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "                session.commit()\n",
    "                updated_face_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "    if updated_face_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "\n",
    "    # Mtcnn-serfiq\n",
    "    query = session.query(FaceImage, CroppedImage) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector)\\\n",
    "        .filter(EmbeddingModel.name == 'ArcFace_normalized', Detector.name == 'mtcnn_serfiq', Detector.name != 'mediapipe')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(FaceImage.embeddings == None)\n",
    "    all_face_img = (query.all())\n",
    "\n",
    "    updated_face_images = []\n",
    "    count = 0\n",
    "\n",
    "    for face_img in tqdm(all_face_img, desc='Computing embeddings DeepFace mtcnn-serfiq'):\n",
    "        embedding = DeepFace.represent(face_img.CroppedImage.get_aligned_image(input_dir, ser_fiq = serfiq), detector_backend='skip',\n",
    "                                    model_name='ArcFace', enforce_detection=False, normalization = 'ArcFace')\n",
    "        face_img.FaceImage.embeddings = embedding\n",
    "        updated_face_images.append({\"faceImage_id\": face_img.FaceImage.faceImage_id, \"embeddings\": face_img.FaceImage.embeddings})\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "                session.commit()\n",
    "                updated_face_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating embeddings for FaceImages in the database\")\n",
    "    if updated_face_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(FaceImage, updated_face_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating embeddings for FaceImages in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def update_quality_images(session, input_dir, serfiq=None, force_update: bool = False):\n",
    "    \n",
    "    update_ser_fiq(session, input_dir, serfiq = serfiq, force_update=force_update)\n",
    "    # update_tface(session, input_dir,  serfiq = serfiq, force_update=force_update)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_ser_fiq(session, input_dir, serfiq=None, force_update: bool = False):\n",
    "    query = session.query(QualityImage, CroppedImage) \\\n",
    "        .join(QualityModel) \\\n",
    "        .join(FaceImage, FaceImage.faceImage_id == QualityImage.faceImage_id) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .join(Detector) \\\n",
    "        .filter(EmbeddingModel.name == 'QMagFace',\n",
    "                QualityModel.name == 'ser_fiq',\n",
    "                Detector.name == 'mtcnn_serfiq')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(QualityImage.quality == None)\n",
    "    all_rows = query.all()\n",
    "\n",
    "    updated_quality_images = []\n",
    "    count = 0\n",
    "\n",
    "    for row in tqdm(all_rows, desc='Computing SER-FIQ quality'):\n",
    "        aligned_img = row.CroppedImage.get_aligned_image(input_dir, ser_fiq=serfiq)\n",
    "        quality = serfiq.get_score(aligned_img, T=100)\n",
    "\n",
    "        row.QualityImage.quality = quality\n",
    "        updated_quality_images.append({\"qualityImage_id\": row.QualityImage.qualityImage_id, \"quality\": row.QualityImage.quality})\n",
    "        count += 1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(QualityImage, updated_quality_images)\n",
    "                session.commit()\n",
    "                updated_quality_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating SER-FIQ quality for QualityImages in the database\")\n",
    "\n",
    "    if updated_quality_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(QualityImage, updated_quality_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating SER-FIQ quality for QualityImages in the database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "\n",
    "def update_ser_fiq_old(session, input_dir, serfiq=None, force_update: bool = False):\n",
    "    query = session.query(QualityImage, CroppedImage) \\\n",
    "        .join(QualityModel) \\\n",
    "        .join(FaceImage, FaceImage.faceImage_id == QualityImage.faceImage_id) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .filter(EmbeddingModel.name == 'QMagFace',\n",
    "                QualityModel.name == 'ser_fiq')\n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(QualityImage.quality == None)\n",
    "    all_rows = query.all()\n",
    "\n",
    "    updated_quality_images = []\n",
    "    count = 0\n",
    "\n",
    "    for row in tqdm(all_rows, desc='Computing SER-FIQ quality'):\n",
    "        aligned_img = row.CroppedImage.get_aligned_image(input_dir, ser_fiq=serfiq)\n",
    "        quality = serfiq.get_score(aligned_img, T=100)\n",
    "\n",
    "        row.QualityImage.quality = quality\n",
    "        updated_quality_images.append({\"qualityImage_id\": row.QualityImage.qualityImage_id, \"quality\": row.QualityImage.quality})\n",
    "        count += 1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            try:\n",
    "                session.bulk_update_mappings(QualityImage, updated_quality_images)\n",
    "                session.commit()\n",
    "                updated_quality_images = []\n",
    "            except:\n",
    "                session.rollback()\n",
    "                raise Exception(\"Error updating SER-FIQ quality for QualityImages in the database\")\n",
    "\n",
    "    if updated_quality_images:\n",
    "        try:\n",
    "            session.bulk_update_mappings(QualityImage, updated_quality_images)\n",
    "            session.commit()\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise Exception(\"Error updating SER-FIQ quality for QualityImages in the database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_ser_fiq_old(session, input_dir, serfiq = None, force_update: bool = False):\n",
    "    \n",
    "    # todo: Now it is only for ArcFace, it should be expanded to other embedding models.\n",
    "    query = session.query(QualityImage, CroppedImage) \\\n",
    "        .join(QualityModel) \\\n",
    "        .join(FaceImage, FaceImage.faceImage_id == QualityImage.faceImage_id) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .filter(EmbeddingModel.name == 'ArcFace',\n",
    "                QualityModel.name == 'ser_fiq')\n",
    "    #    .join(Image, Image.image_id == CroppedImage.image_id) \\\n",
    "       \n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(QualityImage.quality == None)\n",
    "    all_rows = (query.all())\n",
    "\n",
    "    # for row in tqdm(all_rows[:5], desc='TRIM Computing SER-FIQ quality'):\n",
    "    for row in tqdm(all_rows, desc='Computing SER-FIQ quality'):             \n",
    "\n",
    "        aligned_img = row.CroppedImage.get_aligned_image(input_dir, ser_fiq=serfiq) \n",
    "        quality = serfiq.get_score(aligned_img, T=100)\n",
    "        \n",
    "        row.QualityImage.quality = quality\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def update_tface(session, input_dir, serfiq, force_update: bool = False):\n",
    "    ser_fiq = serfiq\n",
    "\n",
    "    net, gpu_available = get_network()\n",
    "\n",
    "    # todo: Now it is only for ArcFace, it should be expanded to other embedding models. \n",
    "    # Is it ArcFace or another face recognition model?\n",
    "    \n",
    "    query = session.query(QualityImage, CroppedImage) \\\n",
    "        .join(QualityModel) \\\n",
    "        .join(FaceImage, FaceImage.faceImage_id == QualityImage.faceImage_id) \\\n",
    "        .join(EmbeddingModel) \\\n",
    "        .join(CroppedImage, CroppedImage.croppedImage_id == FaceImage.croppedImage_id) \\\n",
    "        .filter(EmbeddingModel.name == 'ArcFace', \n",
    "                QualityModel.name == 'tface')\n",
    "        # .join(Image, Image.image_id == CroppedImage.image_id) \n",
    "        \n",
    "\n",
    "    if not force_update:\n",
    "        query = query.filter(QualityImage.quality == None)\n",
    "    all_rows = (query.all())\n",
    "\n",
    "    # for row in tqdm(all_rows[:5], desc='TRIM: Computing TFace quality'): \n",
    "    for row in tqdm(all_rows, desc='Computing TFace quality'):             \n",
    "\n",
    "        aligned_img = row.CroppedImage.get_aligned_image(input_dir, ser_fiq=serfiq) \n",
    "        quality = compute_tf_quality(aligned_img, net, gpu_available=gpu_available)             \n",
    "        \n",
    "        row.QualityImage.quality = quality\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sql-face",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
